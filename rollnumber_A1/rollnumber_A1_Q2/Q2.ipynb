{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imMHq8PVcEFb"
   },
   "source": [
    "## Image Captioning using KNN\n",
    "\n",
    "Although VLMs (Vision Language Models) are the go to tools for image captioning right now, there are interesting works from earlier years that used KNN for captioning and perform surprisingly well enough!\n",
    "\n",
    "Further, Libraries like [Faiss](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) perform the nearest neighbor computation efficiently and are used in many industrial applications.\n",
    "\n",
    "- In this question you will implement an algorithm to perform captioning using KNN based on the paper [A Distributed Representation Based Query Expansion Approach for\n",
    "Image Captioning](https://aclanthology.org/P15-2018.pdf)\n",
    "\n",
    "- Dataset: [MS COCO](https://cocodataset.org/#home) 2014 (val set only)\n",
    "\n",
    "- Algorithm:\n",
    "    1. Given: Image embeddings and correspond caption embeddings (5 Per image)\n",
    "    1. For every image, findout the k nearest images and compute its query vector as the weighted sum of the captions of the nearest images (k*5 captions per image)\n",
    "    1. The predicted caption would be the caption in the dataset that is closest to the query vector. (for the sake of the assignment use the same coco val set captions as the dataset)\n",
    "\n",
    "- The image and text embeddings are extracted from the [CLIP](https://openai.com/research/clip) model. (You need not know about this right now)\n",
    "\n",
    "- Tasks:\n",
    "    1. Implement the algorithm and compute the bleu score. Use Faiss for nearest neighbor computation. Starter code is provided below.\n",
    "    1. Try a few options for k. Record your observations.\n",
    "    1. For a fixed k, try a few options in the Faiss index factory to speed the computation in step 2. Record your observations.\n",
    "    1. Qualitative study: Visualize five images, their ground truth captions and the predicted caption.\n",
    "    \n",
    "Note: Run this notebook on Colab for fastest resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0XAWcEuKvyG",
    "outputId": "8d5eee2c-db1d-4088-f0c5-ec4c5b73d690"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!gdown 1RwhwntZGZ9AX8XtGIDAcQD3ByTcUiOoO #image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWjuVTJkDvM4",
    "outputId": "42b13b0b-b0e2-4443-f4ae-37ea61f768b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!gdown 1b-4hU2Kp93r1nxMUGEgs1UbZov0OqFfW #caption embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7h8e8DunDEK",
    "outputId": "511fb666-1edb-4629-84ca-12469610993b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp311-cp311-win_amd64.whl (10.8 MB)\n",
      "     ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/10.8 MB 2.0 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.3/10.8 MB 3.5 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.4/10.8 MB 3.7 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.4/10.8 MB 3.7 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.0/10.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.2/10.8 MB 4.3 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.4/10.8 MB 4.6 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 1.7/10.8 MB 4.7 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.0/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.2/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.4/10.8 MB 5.0 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.5/10.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 2.9/10.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.1/10.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.3/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.5/10.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 3.7/10.8 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 3.9/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.1/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.2/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 4.5/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 4.7/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 4.9/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 5.2/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 5.4/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 5.7/10.8 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 5.9/10.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 6.1/10.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 6.3/10.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 6.6/10.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 6.8/10.8 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 7.1/10.8 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 7.3/10.8 MB 5.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 7.5/10.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 7.8/10.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 8.0/10.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 8.2/10.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.5/10.8 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 8.7/10.8 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 9.0/10.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 9.3/10.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.5/10.8 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.8/10.8 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 10.1/10.8 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.3/10.8 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.6/10.8 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.8/10.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.8/10.8 MB 5.4 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\pdfstructure-0.0.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!wget http://images.cocodataset.org/zips/val2014.zip\n",
    "!unzip /content/val2014.zip\n",
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
    "!unzip /content/annotations_trainval2014.zip\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI9PuLZ6b51J"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.translate import bleu_score\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igqtoD36iQv8",
    "outputId": "8c0b167b-b772-438f-dda1-e2c556d176f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.58s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of samples:  40504\n",
      "Image Size:  torch.Size([3, 224, 224])\n",
      "['A loft bed with a dresser underneath it.', 'A bed and desk in a small room.', 'Wooden bed on top of a white dresser.', 'A bed sits on top of a dresser and a desk.', 'Bunk bed with a narrow shelf sitting underneath it. ']\n"
     ]
    }
   ],
   "source": [
    "def get_transform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),  # convert the PIL Image to a tensor\n",
    "        transforms.Normalize(\n",
    "            (0.485, 0.456, 0.406),  # normalize image for pre-trained model\n",
    "            (0.229, 0.224, 0.225),\n",
    "        )\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "coco_dset = dset.CocoCaptions(root = '/content/val2014',\n",
    "                        annFile = '/content/annotations/captions_val2014.json',\n",
    "                        transform=get_transform())\n",
    "\n",
    "print('Number of samples: ', len(coco_dset))\n",
    "img, target = coco_dset[3] # load 4th sample\n",
    "\n",
    "print(\"Image Size: \", img.shape)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpjbQ_KUick0",
    "outputId": "9c3f3d6e-757e-4e23-c613-0bd02320fc71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions: (40504, 5)\n"
     ]
    }
   ],
   "source": [
    "ids = list(sorted(coco_dset.coco.imgs.keys()))\n",
    "captions = []\n",
    "for i in range(len(ids)):\n",
    "    captions.append([ele['caption'] for ele in coco_dset.coco.loadAnns(coco_dset.coco.getAnnIds(ids[i]))][:5]) #5 per image\n",
    "captions_np = np.array(captions)\n",
    "print('Captions:', captions_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alKCWuRhivc_",
    "outputId": "240b9882-ac13-4f15-c074-ed9da4446f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total captions: 202520\n"
     ]
    }
   ],
   "source": [
    "captions_flat = captions_np.flatten().tolist()\n",
    "print('Total captions:', len(captions_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "leEngJ4hkzpD",
    "outputId": "d47a6141-d268-49c8-e84d-520ca0c678b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption embeddings (40504, 5, 512)\n"
     ]
    }
   ],
   "source": [
    "cap_path = '/content/coco_captions.npy'\n",
    "caption_embeddings = np.load(cap_path)\n",
    "print('Caption embeddings',caption_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnAdVULXlTNV",
    "outputId": "5a9f9a0d-678d-4a14-ae2b-e6c9d0ec4a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embeddings (40504, 512)\n"
     ]
    }
   ],
   "source": [
    "img_path = '/content/coco_imgs.npy'\n",
    "image_embeddings = np.load(img_path)\n",
    "print('Image embeddings',image_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXzKkgt-lhTo"
   },
   "outputs": [],
   "source": [
    "def accuracy(predict, real):\n",
    "    '''\n",
    "    use bleu score as a measurement of accuracy\n",
    "    :param predict: a list of predicted captions\n",
    "    :param real: a list of actual descriptions\n",
    "    :return: bleu accuracy\n",
    "    '''\n",
    "    accuracy = 0\n",
    "    for i, pre in enumerate(predict):\n",
    "        references = real[i]\n",
    "        score = bleu_score.sentence_bleu(references, pre)\n",
    "        accuracy += score\n",
    "    return accuracy/len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_captioning(image_embeddings, caption_embeddings, k, ground_truth_captions):\n",
    "    # Initialize Faiss index\n",
    "    index = faiss.IndexFlatL2(image_embeddings.shape[1])\n",
    "    index.add(image_embeddings)\n",
    "\n",
    "    predicted_captions = []\n",
    "\n",
    "    for i in range(image_embeddings.shape[0]):\n",
    "        # Find k nearest neighbors\n",
    "        D, I = index.search(image_embeddings[i:i+1], k)\n",
    "\n",
    "        # Compute query vector as the weighted sum of captions of the nearest images\n",
    "        query_vector = np.sum(caption_embeddings[I.flatten()], axis=0)\n",
    "\n",
    "        # Find the caption closest to the query vector using vectorized operations\n",
    "        distances = np.linalg.norm(caption_embeddings - query_vector, axis=1)\n",
    "        closest_caption_index = np.argmin(distances)\n",
    "\n",
    "        # Ensure index is within bounds\n",
    "        closest_caption_index = min(closest_caption_index, len(ground_truth_captions) - 1)\n",
    "        predicted_captions.append(ground_truth_captions[closest_caption_index])\n",
    "\n",
    "    return predicted_captions\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "k_value = 5  # You can experiment with different values of k\n",
    "predicted_captions = knn_captioning(image_embeddings, caption_embeddings, k_value, captions)\n",
    "\n",
    "# Compute BLEU score for each image\n",
    "bleu_scores = [bleu_score.sentence_bleu(captions[i], predicted_captions[i]) for i in range(len(captions))]\n",
    "average_bleu = np.mean(bleu_scores)\n",
    "print(f\"Average BLEU score: {average_bleu}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
