{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvpf93Fv9Hlk"
      },
      "source": [
        "# SMAI Assignment - 2\n",
        "\n",
        "## Question 4: Multi-layer Perceptrons\n",
        "\n",
        "### Digit Classification\n",
        "\n",
        "In this question, you will perform digit classification using MLP. You can use the MLPClassifier from sklearn. Train and two test sets have been provided [here](https://drive.google.com/drive/folders/1OUVrOMp2jSSBDJSqvEyXDFTrhiyZnqit?usp=sharing). Report the accuracy and any other interesting observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G-MpagLl-YJp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cHAbz92352gz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2726, 28, 28, 3)\n",
            "(2726,)\n"
          ]
        }
      ],
      "source": [
        "filename = \"training_3digits.hdf5\"\n",
        "train = h5py.File(filename,'r')\n",
        "train_images = np.array(train['images'])\n",
        "train_digits = np.array(train['digits'])\n",
        "train.close()\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_digits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3147, 28, 28, 3)\n",
            "(3147,)\n"
          ]
        }
      ],
      "source": [
        "filename = \"testing_3digits_part2.hdf5\"\n",
        "test2 = h5py.File(filename,'r')\n",
        "test_images_2 = np.array(test2['images'])\n",
        "test_digits_2 = np.array(test2['digits'])\n",
        "test2.close()\n",
        "\n",
        "print(test_images_2.shape)\n",
        "print(test_digits_2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train images are total of 2726 , each be like 28*28*3. Since there are three channels.\n",
        "Train digits are total of 2726, each corresponding to digit in the photo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5MLBdrs65woF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3147, 28, 28, 3)\n",
            "(3147,)\n"
          ]
        }
      ],
      "source": [
        "filename = \"testing_3digits_part1.hdf5\"\n",
        "test1 = h5py.File(filename,'r')\n",
        "test_images_1 = np.array(test1['images'])\n",
        "test_digits_1 = np.array(test1['digits'])\n",
        "test1.close()\n",
        "\n",
        "print(test_images_1.shape)\n",
        "print(test_digits_1.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display the first image from each set side by side\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot for train_images set\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Train Image set1 [1]')\n",
        "plt.imshow(test_images_1[1])\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot for train_images2 set\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Train Image set2 [2]')\n",
        "plt.imshow(test_images_2[1])\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test Images are total of 3147 ,each be like 28*28*3. Since there are three channels.\n",
        "Test digits are total of 3147, each corresponding to digit in the photo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CASE 1 : DIRECTLY FLATTEN THE IMAGES \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2726, 2352)\n",
            "(3147, 2352)\n",
            "Accuracy Score Test1 1.0\n",
            "Accuracy Score Test2 0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "# directly flatten the train images \n",
        "train_images_flat = train_images.reshape(train_images.shape[0],-1)\n",
        "test_images_flat_1= test_images_1.reshape(test_images_1.shape[0],-1)\n",
        "\n",
        "print(train_images_flat.shape)\n",
        "print(test_images_flat_1.shape)\n",
        "\n",
        "# here noe use MLP classifer to fit on the train images and train digits\n",
        "\n",
        "mlp_1=MLPClassifier(hidden_layer_sizes=(50,),max_iter=100,random_state=42)\n",
        "mlp_1.fit(train_images_flat,train_digits)\n",
        "\n",
        "# now use the trained model to predict the test images\n",
        "predicted_1=mlp_1.predict(test_images_flat_1)\n",
        "print(\"Accuracy Score Test1\",accuracy_score(test_digits_1,predicted_1))\n",
        "\n",
        "test_images_flat_2= test_images_2.reshape(test_images_2.shape[0],-1)\n",
        "predicted_2=mlp_1.predict(test_images_flat_2)\n",
        "print(\"Accuracy Score Test2\",accuracy_score(test_digits_2,predicted_2))\n",
        "\n",
        "\n",
        "                    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CASE 2: CONVERT THEM INTO THE GRAY IMAGES AND THEN FLATTEN THEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# flatten the images for input to the MLP\n",
        "# Flatten the images for MLP input\n",
        "gray_train_images = np.dot(train_images[..., :3], [0.299, 0.587, 0.114])\n",
        "gray_test_images= np.dot(test_images_1[..., :3], [0.299, 0.587, 0.114])\n",
        "\n",
        "# Flatten the images for MLP input\n",
        "gray_images_flattened = gray_train_images.reshape((gray_train_images.shape[0], -1))\n",
        "gray_test_images_flattened = gray_test_images.reshape((gray_test_images.shape[0], -1))\n",
        "\n",
        "gray_test_images_2= np.dot(test_images_2[..., :3], [0.299, 0.587, 0.114])\n",
        "gray_test_images_flattened_2 = gray_test_images_2.reshape((gray_test_images_2.shape[0], -1))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score test1 0.9945980298697172\n",
            "Accuracy Score test2 0.3606609469335875\n"
          ]
        }
      ],
      "source": [
        "# Train MLP Classifier\n",
        "mlp_2=MLPClassifier(hidden_layer_sizes=(50,),max_iter=300,random_state=42)\n",
        "mlp_2.fit(gray_images_flattened, train_digits)\n",
        "print(\"Accuracy Score test1\",accuracy_score(test_digits_1, mlp_2.predict(gray_test_images_flattened)))\n",
        "print(\"Accuracy Score test2\",accuracy_score(test_digits_2, mlp_2.predict(gray_test_images_flattened_2)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:**\n",
        "\n",
        "In the initial analysis, we noted that the accuracy for the first test set was perfect (1.0), while the accuracy for the second test set was zero. This discrepancy prompted further investigation.\n",
        "\n",
        "**Insight:**\n",
        "\n",
        "Upon closer examination, we discovered that the model was trained on color images where the digits were colored. Consequently, the model performed exceptionally well on the first test set, which also contained colored digits.\n",
        "\n",
        "However, the second test set consisted of uncolored digits, leading to a lack of recognition by the initially trained model and resulting in zero accuracy.\n",
        "\n",
        "**Solution:**\n",
        "\n",
        "To address this issue, we experimented with converting the images to grayscale. The grayscale conversion proved to be beneficial, especially for the second test set. The accuracy significantly improved to 30 percent. This enhancement highlights the importance of considering the color characteristics during training and adjusting accordingly for diverse test sets.\n",
        "\n",
        "- The decision on the number of layers and other parameters was iteratively optimized through experiments on various cases. This iterative approach is essential for adapting the model to different scenarios and ensuring robust performance across diverse datasets."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
