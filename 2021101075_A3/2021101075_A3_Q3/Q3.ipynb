{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62d68733ba6a4d6ea472e19645b950e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5aeae31ad9c453fb12e020414386e00",
              "IPY_MODEL_e879eaad2dab4f8382dd9dc121fb0236"
            ],
            "layout": "IPY_MODEL_a34f8b1a4c9541aa9b9007aa0634c01b"
          }
        },
        "c5aeae31ad9c453fb12e020414386e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eafd3b4bfcfd4e0c8e7c2916b4b9e629",
            "placeholder": "​",
            "style": "IPY_MODEL_6b2144f5a09542c8ae0fdc28df1c7c7d",
            "value": "0.010 MB of 0.010 MB uploaded\r"
          }
        },
        "e879eaad2dab4f8382dd9dc121fb0236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad5b1564ead346e7b5221fa878e812a7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_768e8b65eacf4a9287e44b0b4bf372f7",
            "value": 1
          }
        },
        "a34f8b1a4c9541aa9b9007aa0634c01b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eafd3b4bfcfd4e0c8e7c2916b4b9e629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2144f5a09542c8ae0fdc28df1c7c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad5b1564ead346e7b5221fa878e812a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768e8b65eacf4a9287e44b0b4bf372f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2594b977b5234adea4f798bb17f1c2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0c70007de2045cb9cbc28b9999df08a",
              "IPY_MODEL_85b955211056403e83f2558de78fda8b"
            ],
            "layout": "IPY_MODEL_bbb37347f30e426caab4ed4d8584e706"
          }
        },
        "f0c70007de2045cb9cbc28b9999df08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc403fcf3c2d4f64aaf5449055bbfa7b",
            "placeholder": "​",
            "style": "IPY_MODEL_6691fff7827346e7b2975adcb0341d8b",
            "value": "0.016 MB of 0.016 MB uploaded\r"
          }
        },
        "85b955211056403e83f2558de78fda8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_916c09703b0045aeba1d99663b595732",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_517b978e3a5c4f6e9b8db51d4e0c44e8",
            "value": 1
          }
        },
        "bbb37347f30e426caab4ed4d8584e706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc403fcf3c2d4f64aaf5449055bbfa7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6691fff7827346e7b2975adcb0341d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "916c09703b0045aeba1d99663b595732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517b978e3a5c4f6e9b8db51d4e0c44e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afb6ec90d91c496d9360fd8eca128beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eacb45c17e1846f9a45a8370e1269a59",
              "IPY_MODEL_9bc65065bb3b439abb536ea727702111"
            ],
            "layout": "IPY_MODEL_f73d7f5cd5e3417c92cfbd8325ed6a80"
          }
        },
        "eacb45c17e1846f9a45a8370e1269a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07502882222e4dcf901c9158e849f2f4",
            "placeholder": "​",
            "style": "IPY_MODEL_0f382381d4214758a34ab62c954e4c89",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "9bc65065bb3b439abb536ea727702111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9929bac6803749f6898cfc50fd6f039b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9f78ac8bbde40aaabf9ed8293ef7e2c",
            "value": 1
          }
        },
        "f73d7f5cd5e3417c92cfbd8325ed6a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07502882222e4dcf901c9158e849f2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f382381d4214758a34ab62c954e4c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9929bac6803749f6898cfc50fd6f039b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9f78ac8bbde40aaabf9ed8293ef7e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5830f40dcb744e7c84ceaa5533d38dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33ba4b113c2d4259b6900cee177a6e48",
              "IPY_MODEL_9f6b4494fc0e433bb446127c96807d46"
            ],
            "layout": "IPY_MODEL_59fdd64c94a74dd792879c964559dcaf"
          }
        },
        "33ba4b113c2d4259b6900cee177a6e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59982aaa859f4f41ad48cf643a135eec",
            "placeholder": "​",
            "style": "IPY_MODEL_07b27fe805434f1aa92ed0c56f29799b",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "9f6b4494fc0e433bb446127c96807d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5bf668035d42bd903e23fe2855408f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba9272df5e64dee99ea47b62ef1d019",
            "value": 1
          }
        },
        "59fdd64c94a74dd792879c964559dcaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59982aaa859f4f41ad48cf643a135eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b27fe805434f1aa92ed0c56f29799b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc5bf668035d42bd903e23fe2855408f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba9272df5e64dee99ea47b62ef1d019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14cyWQYKbpU8",
        "outputId": "38a18e8d-c171-4e0d-f6c6-6ff3113928a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.43.0-py2.py3-none-any.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.42 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.43.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltEQ-sUobK7N",
        "outputId": "ea320f7a-c1cb-4a76-b015-15efea76de0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-26 17:03:46--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘../data/aclImdb_v1.tar.gz’\n",
            "\n",
            "../data/aclImdb_v1. 100%[===================>]  80.23M  5.66MB/s    in 7.3s    \n",
            "\n",
            "2024-03-26 17:03:54 (11.0 MB/s) - ‘../data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir ../data\n",
        "!wget -O ../data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -zxf ../data/aclImdb_v1.tar.gz -C ../data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def read_imdb_data(data_dir='../data/aclImdb'):\n",
        "    data = {}\n",
        "    labels = {}\n",
        "\n",
        "    for data_type in ['train', 'test']:\n",
        "        data[data_type] = {}\n",
        "        labels[data_type] = {}\n",
        "\n",
        "        for sentiment in ['pos', 'neg']:\n",
        "            data[data_type][sentiment] = []\n",
        "            labels[data_type][sentiment] = []\n",
        "\n",
        "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
        "            files = glob.glob(path)\n",
        "\n",
        "            for f in files:\n",
        "                with open(f) as review:\n",
        "                    data[data_type][sentiment].append(review.read())\n",
        "                    # Here we represent a positive review by '1' and a negative review by '0'\n",
        "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
        "\n",
        "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
        "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
        "\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "Vi3llbw0b9uo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = read_imdb_data()\n",
        "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
        "            len(data['train']['pos']), len(data['train']['neg']),\n",
        "            len(data['test']['pos']), len(data['test']['neg'])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MdvyAZ1cZXb",
        "outputId": "8d3a508c-d0b7-4b42-e26b-49ad67f36e88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "def prepare_imdb_data(data, labels):\n",
        "    #Combine positive and negative reviews and labels\n",
        "    data_train = data['train']['pos'] + data['train']['neg']\n",
        "    data_test = data['test']['pos'] + data['test']['neg']\n",
        "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
        "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
        "\n",
        "    #Shuffle reviews and corresponding labels within training and test sets\n",
        "    data_train, labels_train = shuffle(data_train, labels_train)\n",
        "    data_test, labels_test = shuffle(data_test, labels_test)\n",
        "\n",
        "    # Return a unified training data, test data, training labels, test labels\n",
        "    return data_train, data_test, labels_train, labels_test"
      ],
      "metadata": {
        "id": "WP91n_jbcblo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
        "print(len(train_X))\n",
        "print(len(train_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B-3MZJsdBXV",
        "outputId": "b35e6aed-5ee5-4000-d95d-4050d0ce1215"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n",
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step in processing the reviews is to make sure that any html tags that appear should be removed. In addition we wish to tokenize our input, that way words such as entertained and entertaining are considered the same with regard to sentiment analysis."
      ],
      "metadata": {
        "id": "XdEj0NmNd0xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary cleaning Libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n"
      ],
      "metadata": {
        "id": "ZVpEp1E-KTaS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def review_to_words(review):\n",
        "    nltk.download(\"stopwords\", quiet=True)\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
        "    words = text.split() # Split string into words\n",
        "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
        "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
        "\n",
        "    return words"
      ],
      "metadata": {
        "id": "ZGE14NCJdE9c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[100])\n",
        "review_to_words(train_X[100])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkh7ihayerPG",
        "outputId": "7c61e2e7-6fc7-40d4-8951-48b1e9adc3b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This movie was almost intolerable to sit through. I can get beyond the fact that it looks like it was shot with a home video camera and that this movie is supposed to span over weeks in time yet the characters do not once change outfits, but the acting broke the 4th wall to pieces for me. I've seen better acting in a 4th grade play. Aside from that the plot is unrealistic. If the man suspected the guy he would have turned him in. I was also heavily disappointed that all the killings were done with a gun what kind of gore is that. That is not a copycat the Zodiac did not kill using just a gun the authorities would have known it wasn't him. Another thing that really bothered me was that they called Disassociative Identity Disorder DSM 4 when that is the name of the book used to diagnose people with mental disorders not the name of the disorder. Overall I think this movie is not the kind of movie that could be done with a low budget at least not as low as they had or they could have made sure they had better actors or more gore. Plenty of people have went the low budget route with out having to use horrible actors look at Easy Rider that had Dennis Hopper and Jack Nicholson and a low budget.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movi',\n",
              " 'almost',\n",
              " 'intoler',\n",
              " 'sit',\n",
              " 'get',\n",
              " 'beyond',\n",
              " 'fact',\n",
              " 'look',\n",
              " 'like',\n",
              " 'shot',\n",
              " 'home',\n",
              " 'video',\n",
              " 'camera',\n",
              " 'movi',\n",
              " 'suppos',\n",
              " 'span',\n",
              " 'week',\n",
              " 'time',\n",
              " 'yet',\n",
              " 'charact',\n",
              " 'chang',\n",
              " 'outfit',\n",
              " 'act',\n",
              " 'broke',\n",
              " '4th',\n",
              " 'wall',\n",
              " 'piec',\n",
              " 'seen',\n",
              " 'better',\n",
              " 'act',\n",
              " '4th',\n",
              " 'grade',\n",
              " 'play',\n",
              " 'asid',\n",
              " 'plot',\n",
              " 'unrealist',\n",
              " 'man',\n",
              " 'suspect',\n",
              " 'guy',\n",
              " 'would',\n",
              " 'turn',\n",
              " 'also',\n",
              " 'heavili',\n",
              " 'disappoint',\n",
              " 'kill',\n",
              " 'done',\n",
              " 'gun',\n",
              " 'kind',\n",
              " 'gore',\n",
              " 'copycat',\n",
              " 'zodiac',\n",
              " 'kill',\n",
              " 'use',\n",
              " 'gun',\n",
              " 'author',\n",
              " 'would',\n",
              " 'known',\n",
              " 'anoth',\n",
              " 'thing',\n",
              " 'realli',\n",
              " 'bother',\n",
              " 'call',\n",
              " 'disassoci',\n",
              " 'ident',\n",
              " 'disord',\n",
              " 'dsm',\n",
              " '4',\n",
              " 'name',\n",
              " 'book',\n",
              " 'use',\n",
              " 'diagnos',\n",
              " 'peopl',\n",
              " 'mental',\n",
              " 'disord',\n",
              " 'name',\n",
              " 'disord',\n",
              " 'overal',\n",
              " 'think',\n",
              " 'movi',\n",
              " 'kind',\n",
              " 'movi',\n",
              " 'could',\n",
              " 'done',\n",
              " 'low',\n",
              " 'budget',\n",
              " 'least',\n",
              " 'low',\n",
              " 'could',\n",
              " 'made',\n",
              " 'sure',\n",
              " 'better',\n",
              " 'actor',\n",
              " 'gore',\n",
              " 'plenti',\n",
              " 'peopl',\n",
              " 'went',\n",
              " 'low',\n",
              " 'budget',\n",
              " 'rout',\n",
              " 'use',\n",
              " 'horribl',\n",
              " 'actor',\n",
              " 'look',\n",
              " 'easi',\n",
              " 'rider',\n",
              " 'denni',\n",
              " 'hopper',\n",
              " 'jack',\n",
              " 'nicholson',\n",
              " 'low',\n",
              " 'budget']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_reviews_by_word_count(reviews, labels, min_words, max_words):\n",
        "    filtered_reviews = []\n",
        "    filtered_labels = []\n",
        "    for review, label in zip(reviews, labels):\n",
        "        num_words = len(review)\n",
        "        if min_words <= num_words <= max_words:\n",
        "            filtered_reviews.append(review)\n",
        "            filtered_labels.append(label)\n",
        "    return filtered_reviews, filtered_labels"
      ],
      "metadata": {
        "id": "IiV-59e1vPnE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "cache_dir = \"../data\"  # where to store cache files\n",
        "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
        "\n",
        "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
        "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
        "    \"\"\"Convert each review to words; read from cache if available.\"\"\"\n",
        "\n",
        "    # If cache_file is not None, try to read from it first\n",
        "    cache_data = None\n",
        "    if cache_file is not None:\n",
        "        try:\n",
        "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
        "                cache_data = pickle.load(f)\n",
        "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
        "        except:\n",
        "            pass  # unable to read from cache, but that's okay\n",
        "\n",
        "    # If cache is missing, then do the heavy lifting\n",
        "    if cache_data is None:\n",
        "        # Preprocess training and test data to obtain words for each review\n",
        "        #words_train = list(map(review_to_words, data_train))\n",
        "        #words_test = list(map(review_to_words, data_test))\n",
        "        words_train = [review_to_words(review) for review in data_train]\n",
        "        words_test = [review_to_words(review) for review in data_test]\n",
        "\n",
        "        words_train, labels_train = filter_reviews_by_word_count(words_train, labels_train, min_words=100, max_words=500)\n",
        "        words_test, labels_test = filter_reviews_by_word_count(words_test, labels_test, min_words=100, max_words=500)\n",
        "\n",
        "        # Write to cache file for future runs\n",
        "        if cache_file is not None:\n",
        "            cache_data = dict(words_train=words_train, words_test=words_test,\n",
        "                              labels_train=labels_train, labels_test=labels_test)\n",
        "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
        "                pickle.dump(cache_data, f)\n",
        "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
        "    else:\n",
        "        # Unpack data loaded from cache file\n",
        "        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
        "                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
        "\n",
        "    return words_train, words_test, labels_train, labels_test\n"
      ],
      "metadata": {
        "id": "luRLaCMgeyyP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X, train_y, test_y = preprocess_data(train_X, test_X, train_y, test_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MaPkbAxwXJR",
        "outputId": "2b752dc2-e841-4504-d79f-27004bd72714"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-3545aefb4b3a>:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote preprocessed data to cache file: preprocessed_data.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the size of the validation set (20% of the training data)\n",
        "val_size = int(0.2 * len(train_X))\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "val_X = train_X[:val_size]\n",
        "val_y = train_y[:val_size]\n",
        "\n",
        "# Update the training data to exclude the validation set\n",
        "train_X = train_X[val_size:]\n",
        "train_y = train_y[val_size:]\n"
      ],
      "metadata": {
        "id": "Nm-EqWn4fLc0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QySzRBWATrRB",
        "outputId": "b02c5f2f-dfe9-4583-bf87-d1067b3177cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we will be using a recurrent neural network, it will be convenient if the length of each review is the same. To do this, we will fix a size for our reviews and then pad short reviews with the category 'no word' (which we will label 0) and truncate long reviews. Basically in the dictionary the one with the most higher rank is the one that occurs most frequently. You dont care for the first two these are no words"
      ],
      "metadata": {
        "id": "__DN0F4syJkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7bgt70phy7sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def build_dict(data, vocab_size = 5000):\n",
        "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
        "    word_count = {}\n",
        "\n",
        "    for sentence in data:\n",
        "        for word in sentence:\n",
        "            if word in word_count:\n",
        "                word_count[word] += 1\n",
        "            else:\n",
        "                word_count[word] = 1\n",
        "\n",
        "    # DONE: Sort the words found in `data` so that sorted_words[0] is the most frequently appearing word and\n",
        "    #       sorted_words[-1] is the least frequently appearing word.\n",
        "\n",
        "    sorted_words = sorted(word_count, key=word_count.get, reverse=True)\n",
        "    print(\"this is the first word having most frequency\",sorted_words[0])\n",
        "    print(\"this is the word having least frequency\",sorted_words[-1])\n",
        "\n",
        "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
        "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): # The -2 is so that we save room for the 'no word'\n",
        "        word_dict[word] = idx + 2                              # 'infrequent' labels\n",
        "\n",
        "    return word_dict"
      ],
      "metadata": {
        "id": "MPbg30bJwa_U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "data_dir = '../data'  # The folder we will use for storing data\n",
        "word_dict_file = os.path.join(data_dir, 'word_dict.pkl')\n",
        "\n",
        "if os.path.exists(word_dict_file):\n",
        "    # If the word dictionary file exists, load it\n",
        "    with open(word_dict_file, \"rb\") as f:\n",
        "        word_dict = pickle.load(f)\n",
        "    print(\"Loaded word dictionary from:\", word_dict_file)\n",
        "else:\n",
        "    # If the word dictionary file doesn't exist, build it\n",
        "    word_dict = build_dict(train_X)\n",
        "    with open(word_dict_file, \"wb\") as f:\n",
        "        pickle.dump(word_dict, f)\n",
        "    print(\"Built and saved word dictionary to:\", word_dict_file)\n",
        "\n",
        "print(list(word_dict.keys())[0:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4vliUPYy6g5",
        "outputId": "9632a6ca-e8bb-4d14-ccf1-3d4e718816a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the first word having most frequency film\n",
            "this is the word having least frequency tablecloth\n",
            "Built and saved word dictionary to: ../data/word_dict.pkl\n",
            "['film', 'movi', 'one', 'like', 'make']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our word dictionary which allows us to transform the words appearing in the reviews into integers, it is time to make use of it and convert our reviews to their integer sequence representation, making sure to pad or truncate to a fixed length, which in our case is 500."
      ],
      "metadata": {
        "id": "5FbCg7lP0kM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_and_pad(word_dict, sentence, pad=500):\n",
        "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
        "    INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
        "\n",
        "    working_sentence = [NOWORD] * pad\n",
        "\n",
        "    for word_index, word in enumerate(sentence[:pad]):\n",
        "        if word in word_dict:\n",
        "            working_sentence[word_index] = word_dict[word]\n",
        "        else:\n",
        "            working_sentence[word_index] = INFREQ\n",
        "\n",
        "    return working_sentence, min(len(sentence), pad)"
      ],
      "metadata": {
        "id": "FRMKuC5R1SGU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_and_pad_data(word_dict, data, pad=500):\n",
        "    result = []\n",
        "    lengths = []\n",
        "\n",
        "    for sentence in data:\n",
        "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
        "        result.append(converted)\n",
        "        lengths.append(leng)\n",
        "\n",
        "    return np.array(result), np.array(lengths)"
      ],
      "metadata": {
        "id": "6Ze7Qf851PzD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
        "test_X, test_X_len = convert_and_pad_data(word_dict, test_X)\n",
        "val_X,val_X_len=convert_and_pad_data(word_dict,val_X)\n"
      ],
      "metadata": {
        "id": "-76tjVYQ0rgd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "data_dir = '../data'  # The folder we will use for storing data\n",
        "train_csv_file = os.path.join(data_dir, 'train.csv')\n",
        "\n",
        "if not os.path.exists(train_csv_file):\n",
        "    # If the train.csv file doesn't exist, create it\n",
        "    pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1) \\\n",
        "        .to_csv(train_csv_file, header=False, index=False)\n",
        "    print(\"Created train.csv file:\", train_csv_file)\n",
        "else:\n",
        "    print(\"train.csv file already exists, skipping creation.\")"
      ],
      "metadata": {
        "id": "ymhimb1v1bK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383a2a98-acdf-4440-837f-12d05eeb08a6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created train.csv file: ../data/train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '../data'  # The folder we will use for storing data\n",
        "val_csv_file = os.path.join(data_dir, 'val.csv')\n",
        "\n",
        "if not os.path.exists(val_csv_file):\n",
        "    # If the train.csv file doesn't exist, create it\n",
        "    pd.concat([pd.DataFrame(val_y), pd.DataFrame(val_X_len), pd.DataFrame(val_X)], axis=1) \\\n",
        "        .to_csv(val_csv_file, header=False, index=False)\n",
        "    print(\"Created val.csv file:\", val_csv_file)\n",
        "else:\n",
        "    print(\"val.csv file already exists, skipping creation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeOjSyVDfl4g",
        "outputId": "83cfb8a3-4b91-4ea1-c712-12d96b2b490e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created val.csv file: ../data/val.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([pd.DataFrame(test_y), pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1) \\\n",
        "        .to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)"
      ],
      "metadata": {
        "id": "m5ULe-mIjU4R"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[0])\n",
        "print(train_X_len[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXnpy_sr2BMI",
        "outputId": "55d13e1f-f2ce-4f92-ea25-111cd4fa109f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  23   17 2058 3920  827    1  461  195  518  126    5 1553 1829  259\n",
            "   12  146  466 2439  135  354   22   42  100   41 1554   67   83  877\n",
            "  920 3129  677  160  343  139  920 1809  620 1180  106 1582 3522 1106\n",
            "  350  312 1282  166  840  148  416  266  677 2013 1694   20  311    7\n",
            "  273  195  220 1349  484 1029  137 1269   63  894 4994  458  575   89\n",
            " 2058 3920  846  780  285   49   63   33  304  330 1461  135    9 3964\n",
            " 4414 2180  587 1109  477    2   47   20  957  344  706   44   71 2308\n",
            "  137 2815    1   28  162  160  832  466  485   68  596   20  113  729\n",
            "  501    8    2 1127  143  126  776   85  458 1355 3920   41  174  142\n",
            "   20  113 1293  503  964  235   65  401 4994  816 3130  982 1033  891\n",
            "  620  982  113    1    2  549 1129    1 1810  137  287 3131 3132  461\n",
            "  146 1025 1002   31  677 2323 2560 3522  218  227    1  989  135  419\n",
            "  232  305 1428    1   19    1   89 1269   43 1783    1 2888  163  771\n",
            "  800  472  216 1796  588   77  135 2423   31 1642    1  350    1  315\n",
            " 2163    1 2213   51   49   33   79 1706   21   15    2  215  294  104\n",
            "  907 1656  167 2439  222   79 1387  392  354    1 4895  202  295 3061\n",
            " 1011 2689    2  147  380  267 1388  106   47  218   22 4994  436   43\n",
            "  242  160  227 4415  877  251    1   24   69  113  383  583  259  920\n",
            " 1462 1538 1105    1  392    1 2013 1694  289    9  508 4994    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0]\n",
            "264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    \"\"\" RNNClassifier class for initializing the layers for the simple\n",
        "    recurrent neural network model (RNN) used for Sentiment Analysis of\n",
        "    IMDB reviews.\n",
        "\n",
        "    Attributes:\n",
        "        embedding_dim (int): Dimensionality of the embedding layer\n",
        "        hidden_dim (int): Dimensionality of the hidden layer(s)\n",
        "        vocab_size (int): Size of the vocabulary used by Bag of Words\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.dense = nn.Linear(hidden_dim, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "        self.word_dict = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        lengths = x[:, 0]  # Extract lengths from the input\n",
        "        reviews = x[:, 1:]  # Extract reviews from the input\n",
        "        embeds = self.embedding(reviews)\n",
        "        rnn_out, _ = self.rnn(embeds)\n",
        "        out = self.dense(rnn_out[:, -1, :])  # Select the last time step's output\n",
        "        return self.sig(out.squeeze())\n"
      ],
      "metadata": {
        "id": "EiSC4oT3SfZh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    \"\"\" LSTMClassifier class for initializing the layers for the simple\n",
        "    recurrent neural network model (RNN) used for Sentiment Analysis of\n",
        "    IMDB reviews.\n",
        "\n",
        "    Attributes:\n",
        "        embedding_dim (int) dimensionality of the embedding layer\n",
        "        hidden_dim (int) dimensionality of the hidden layer(s)\n",
        "        vocab_size (int) size of the vocabulary used by Bag of Words\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "        self.word_dict = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.t()\n",
        "        lengths = x[0,:]\n",
        "        reviews = x[1:,:]\n",
        "        embeds = self.embedding(reviews)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        out = self.dense(lstm_out)\n",
        "        out = out[lengths - 1, range(len(lengths))]\n",
        "        return self.sig(out.squeeze())"
      ],
      "metadata": {
        "id": "B8GPHB2j3DKR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Function to evaluate the model on a given dataset.\n",
        "\n",
        "    Args:\n",
        "    - model: the PyTorch model to evaluate\n",
        "    - dataloader: DataLoader object for the dataset\n",
        "    - loss_fn: loss function used for training\n",
        "    - device: device to run the evaluation on (e.g., \"cpu\" or \"cuda\")\n",
        "\n",
        "    Returns:\n",
        "    - accuracy: accuracy of the model on the dataset\n",
        "    - loss: average loss on the dataset\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during evaluation\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Compute accuracy\n",
        "            predicted = torch.round(outputs)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "\n",
        "    return accuracy, avg_loss\n"
      ],
      "metadata": {
        "id": "9MgKllOoin8K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, epochs, optimizer, loss_fn, device):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            batch_X, batch_y = batch\n",
        "\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch_X)\n",
        "            loss = loss_fn(output, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.data.item()\n",
        "\n",
        "        # Validation phase\n",
        "        val_accuracy, val_loss = evaluate(model, val_loader, loss_fn, device)\n",
        "\n",
        "        # Calculate average training loss\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Print and log the losses\n",
        "        print(\"Epoch: {}, Train Loss: {:.4f}, Val Loss: {:.4f}, Val Accuracy: {:.4f}\".format(epoch, avg_train_loss, val_loss, val_accuracy))\n",
        "        wandb.log({\"train_loss\": avg_train_loss, \"val_loss\": val_loss})\n"
      ],
      "metadata": {
        "id": "CCz9fSlxiu9M"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "# Read in only the first 250 rows\n",
        "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None)\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "train_sample_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
        "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
        "\n",
        "# Read in only the first 250 rows\n",
        "val_sample = pd.read_csv(os.path.join(data_dir, 'val.csv'), header=None, names=None)\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "val_sample_y = torch.from_numpy(val_sample[[0]].values).float().squeeze()\n",
        "val_sample_X = torch.from_numpy(val_sample.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "val_sample_ds = torch.utils.data.TensorDataset(val_sample_X, val_sample_y)\n",
        "\n",
        "test_sample = pd.read_csv(os.path.join(data_dir, 'test.csv'), header=None, names=None)\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "test_sample_y = torch.from_numpy(test_sample[[0]].values).float().squeeze()\n",
        "test_sample_X = torch.from_numpy(test_sample.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "test_sample_ds = torch.utils.data.TensorDataset(test_sample_X, test_sample_y)"
      ],
      "metadata": {
        "id": "5F4hfzw4ix8t"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "WQAZDtikrzCV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key=\"ac8ef4bdae5edab6284aaf71af5502f523fcb79f\")\n",
        "# Define hyperparameter configurations\n",
        "hyperparameters = [\n",
        "    {\"embedding_dim\": 32, \"hidden_dim\": 64, \"batch_size\": 64},\n",
        "    {\"embedding_dim\": 64, \"hidden_dim\": 128, \"batch_size\": 128},\n",
        "    {\"embedding_dim\": 128, \"hidden_dim\": 256, \"batch_size\": 128},\n",
        "    {\"embedding_dim\": 256, \"hidden_dim\": 512, \"batch_size\": 512},\n",
        "    {\"embedding_dim\": 512, \"hidden_dim\": 1024, \"batch_size\": 512},\n",
        "]\n",
        "\n",
        "# Initialize Wandb\n",
        "wandb.init(project=\"hyperparameter-tuning_LSTM\", name=\"LSTM_Experiment\")\n",
        "\n",
        "# Experiment loop\n",
        "for i, config in enumerate(hyperparameters, 1):\n",
        "    config_name = f\"run_{i}\"\n",
        "    train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=config[\"batch_size\"])\n",
        "    test_sample_dl = torch.utils.data.DataLoader(test_sample_ds,  batch_size=config[\"batch_size\"])\n",
        "    val_sample_dl = torch.utils.data.DataLoader(val_sample_ds,  batch_size=config[\"batch_size\"])\n",
        "\n",
        "\n",
        "    # Create model with specified hyperparameters\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = LSTMClassifier(config[\"embedding_dim\"], config[\"hidden_dim\"], vocab_size=5000).to(device)\n",
        "\n",
        "    # Define optimizer and loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "    # Train the model\n",
        "    train(model, train_sample_dl,val_sample_dl, 15, optimizer, loss_fn, device)\n",
        "\n",
        "    # Evaluate the model on validation set\n",
        "    accuracy, avg_loss = evaluate(model, test_sample_dl, loss_fn, device)\n",
        "\n",
        "    # Log metrics using Wandb\n",
        "    print(f\"LSTM Run {i}: Accuracy on validation set: {accuracy:.4f}, Average loss on validation set: {avg_loss:.4f}\")\n",
        "    wandb.log({\"run\":i,\"accuracy\": accuracy, \"avg_loss\": avg_loss})\n",
        "\n",
        "    # Finish Wandb run\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "62d68733ba6a4d6ea472e19645b950e2",
            "c5aeae31ad9c453fb12e020414386e00",
            "e879eaad2dab4f8382dd9dc121fb0236",
            "a34f8b1a4c9541aa9b9007aa0634c01b",
            "eafd3b4bfcfd4e0c8e7c2916b4b9e629",
            "6b2144f5a09542c8ae0fdc28df1c7c7d",
            "ad5b1564ead346e7b5221fa878e812a7",
            "768e8b65eacf4a9287e44b0b4bf372f7",
            "2594b977b5234adea4f798bb17f1c2dc",
            "f0c70007de2045cb9cbc28b9999df08a",
            "85b955211056403e83f2558de78fda8b",
            "bbb37347f30e426caab4ed4d8584e706",
            "fc403fcf3c2d4f64aaf5449055bbfa7b",
            "6691fff7827346e7b2975adcb0341d8b",
            "916c09703b0045aeba1d99663b595732",
            "517b978e3a5c4f6e9b8db51d4e0c44e8"
          ]
        },
        "id": "CTE4uk0Qvo_J",
        "outputId": "35e42cc5-6484-4cbd-dc76-63c610c44f11"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:ymov58py) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62d68733ba6a4d6ea472e19645b950e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">LSTM_Experiment</strong> at: <a href='https://wandb.ai/prisha/hyperparameter-tuning_LSTM/runs/ymov58py/workspace' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_LSTM/runs/ymov58py/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240326_173127-ymov58py/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:ymov58py). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240326_173206-zknl8ox1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prisha/hyperparameter-tuning_LSTM/runs/zknl8ox1/workspace' target=\"_blank\">LSTM_Experiment</a></strong> to <a href='https://wandb.ai/prisha/hyperparameter-tuning_LSTM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prisha/hyperparameter-tuning_LSTM' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_LSTM</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prisha/hyperparameter-tuning_LSTM/runs/zknl8ox1/workspace' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_LSTM/runs/zknl8ox1/workspace</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 0.6821, Val Loss: 0.6620, Val Accuracy: 0.5966\n",
            "Epoch: 2, Train Loss: 0.6335, Val Loss: 0.6005, Val Accuracy: 0.6659\n",
            "Epoch: 3, Train Loss: 0.5518, Val Loss: 0.5483, Val Accuracy: 0.7250\n",
            "Epoch: 4, Train Loss: 0.5096, Val Loss: 0.5020, Val Accuracy: 0.7636\n",
            "Epoch: 5, Train Loss: 0.4165, Val Loss: 0.5142, Val Accuracy: 0.7697\n",
            "Epoch: 6, Train Loss: 0.3843, Val Loss: 0.5062, Val Accuracy: 0.7762\n",
            "Epoch: 7, Train Loss: 0.3348, Val Loss: 0.4381, Val Accuracy: 0.8153\n",
            "Epoch: 8, Train Loss: 0.2967, Val Loss: 0.4123, Val Accuracy: 0.8208\n",
            "Epoch: 9, Train Loss: 0.2707, Val Loss: 0.5252, Val Accuracy: 0.8050\n",
            "Epoch: 10, Train Loss: 0.2483, Val Loss: 0.4601, Val Accuracy: 0.8208\n",
            "Epoch: 11, Train Loss: 0.2384, Val Loss: 0.4429, Val Accuracy: 0.8157\n",
            "Epoch: 12, Train Loss: 0.2142, Val Loss: 0.4350, Val Accuracy: 0.8292\n",
            "Epoch: 13, Train Loss: 0.1914, Val Loss: 0.4475, Val Accuracy: 0.8292\n",
            "Epoch: 14, Train Loss: 0.1651, Val Loss: 0.4605, Val Accuracy: 0.8153\n",
            "Epoch: 15, Train Loss: 0.1682, Val Loss: 0.5315, Val Accuracy: 0.7673\n",
            "LSTM Run 1: Accuracy on validation set: 0.7576, Average loss on validation set: 0.5791\n",
            "Epoch: 1, Train Loss: 0.6636, Val Loss: 0.6151, Val Accuracy: 0.6617\n",
            "Epoch: 2, Train Loss: 0.5870, Val Loss: 0.5632, Val Accuracy: 0.7013\n",
            "Epoch: 3, Train Loss: 0.5142, Val Loss: 0.5033, Val Accuracy: 0.7459\n",
            "Epoch: 4, Train Loss: 0.4536, Val Loss: 0.4806, Val Accuracy: 0.7645\n",
            "Epoch: 5, Train Loss: 0.3868, Val Loss: 0.4314, Val Accuracy: 0.8050\n",
            "Epoch: 6, Train Loss: 0.4081, Val Loss: 0.4311, Val Accuracy: 0.8027\n",
            "Epoch: 7, Train Loss: 0.3402, Val Loss: 0.4245, Val Accuracy: 0.8171\n",
            "Epoch: 8, Train Loss: 0.2738, Val Loss: 0.4424, Val Accuracy: 0.8260\n",
            "Epoch: 9, Train Loss: 0.2517, Val Loss: 0.4394, Val Accuracy: 0.8325\n",
            "Epoch: 10, Train Loss: 0.3758, Val Loss: 0.5169, Val Accuracy: 0.7604\n",
            "Epoch: 11, Train Loss: 0.2542, Val Loss: 0.4346, Val Accuracy: 0.8292\n",
            "Epoch: 12, Train Loss: 0.1970, Val Loss: 0.4491, Val Accuracy: 0.8208\n",
            "Epoch: 13, Train Loss: 0.1634, Val Loss: 0.4641, Val Accuracy: 0.8255\n",
            "Epoch: 14, Train Loss: 0.1455, Val Loss: 0.4946, Val Accuracy: 0.8208\n",
            "Epoch: 15, Train Loss: 0.1243, Val Loss: 0.5198, Val Accuracy: 0.8171\n",
            "LSTM Run 2: Accuracy on validation set: 0.8132, Average loss on validation set: 0.5659\n",
            "Epoch: 1, Train Loss: 0.6536, Val Loss: 1.2927, Val Accuracy: 0.5831\n",
            "Epoch: 2, Train Loss: 0.5896, Val Loss: 0.5044, Val Accuracy: 0.7613\n",
            "Epoch: 3, Train Loss: 0.4734, Val Loss: 0.7223, Val Accuracy: 0.6673\n",
            "Epoch: 4, Train Loss: 0.5174, Val Loss: 0.4772, Val Accuracy: 0.7813\n",
            "Epoch: 5, Train Loss: 0.3827, Val Loss: 0.4453, Val Accuracy: 0.7925\n",
            "Epoch: 6, Train Loss: 0.3613, Val Loss: 0.4436, Val Accuracy: 0.8013\n",
            "Epoch: 7, Train Loss: 0.3359, Val Loss: 0.4553, Val Accuracy: 0.7990\n",
            "Epoch: 8, Train Loss: 0.5194, Val Loss: 0.4845, Val Accuracy: 0.7687\n",
            "Epoch: 9, Train Loss: 0.3593, Val Loss: 0.5405, Val Accuracy: 0.7469\n",
            "Epoch: 10, Train Loss: 0.2889, Val Loss: 0.4502, Val Accuracy: 0.8143\n",
            "Epoch: 11, Train Loss: 0.2266, Val Loss: 0.4887, Val Accuracy: 0.8208\n",
            "Epoch: 12, Train Loss: 0.2034, Val Loss: 0.5132, Val Accuracy: 0.8069\n",
            "Epoch: 13, Train Loss: 0.1822, Val Loss: 0.5146, Val Accuracy: 0.8134\n",
            "Epoch: 14, Train Loss: 0.1514, Val Loss: 0.5321, Val Accuracy: 0.7915\n",
            "Epoch: 15, Train Loss: 0.1283, Val Loss: 0.5548, Val Accuracy: 0.7906\n",
            "LSTM Run 3: Accuracy on validation set: 0.7938, Average loss on validation set: 0.5609\n",
            "Epoch: 1, Train Loss: 0.6424, Val Loss: 0.6032, Val Accuracy: 0.6645\n",
            "Epoch: 2, Train Loss: 0.5788, Val Loss: 0.5610, Val Accuracy: 0.6896\n",
            "Epoch: 3, Train Loss: 0.4829, Val Loss: 0.4773, Val Accuracy: 0.7631\n",
            "Epoch: 4, Train Loss: 0.4336, Val Loss: 0.4771, Val Accuracy: 0.7711\n",
            "Epoch: 5, Train Loss: 0.3892, Val Loss: 0.4404, Val Accuracy: 0.8106\n",
            "Epoch: 6, Train Loss: 0.3133, Val Loss: 0.4084, Val Accuracy: 0.8199\n",
            "Epoch: 7, Train Loss: 0.2739, Val Loss: 0.4395, Val Accuracy: 0.8255\n",
            "Epoch: 8, Train Loss: 0.2180, Val Loss: 0.4872, Val Accuracy: 0.8008\n",
            "Epoch: 9, Train Loss: 0.2556, Val Loss: 0.5115, Val Accuracy: 0.7711\n",
            "Epoch: 10, Train Loss: 0.2164, Val Loss: 0.5522, Val Accuracy: 0.7804\n",
            "Epoch: 11, Train Loss: 0.1899, Val Loss: 0.5148, Val Accuracy: 0.7985\n",
            "Epoch: 12, Train Loss: 0.1245, Val Loss: 0.5558, Val Accuracy: 0.8246\n",
            "Epoch: 13, Train Loss: 0.0877, Val Loss: 0.6259, Val Accuracy: 0.8120\n",
            "Epoch: 14, Train Loss: 0.0635, Val Loss: 0.6635, Val Accuracy: 0.7999\n",
            "Epoch: 15, Train Loss: 0.0607, Val Loss: 0.6958, Val Accuracy: 0.7687\n",
            "LSTM Run 4: Accuracy on validation set: 0.7560, Average loss on validation set: 0.7414\n",
            "Epoch: 1, Train Loss: 0.7886, Val Loss: 0.6543, Val Accuracy: 0.5919\n",
            "Epoch: 2, Train Loss: 0.6318, Val Loss: 0.6383, Val Accuracy: 0.6133\n",
            "Epoch: 3, Train Loss: 0.5993, Val Loss: 0.6047, Val Accuracy: 0.6454\n",
            "Epoch: 4, Train Loss: 0.5411, Val Loss: 0.5658, Val Accuracy: 0.6757\n",
            "Epoch: 5, Train Loss: 0.5177, Val Loss: 0.5729, Val Accuracy: 0.6724\n",
            "Epoch: 6, Train Loss: 0.4478, Val Loss: 0.4859, Val Accuracy: 0.7566\n",
            "Epoch: 7, Train Loss: 0.3670, Val Loss: 0.4713, Val Accuracy: 0.7687\n",
            "Epoch: 8, Train Loss: 0.2864, Val Loss: 0.4984, Val Accuracy: 0.7580\n",
            "Epoch: 9, Train Loss: 0.2354, Val Loss: 0.5007, Val Accuracy: 0.7729\n",
            "Epoch: 10, Train Loss: 0.1970, Val Loss: 0.5423, Val Accuracy: 0.7487\n",
            "Epoch: 11, Train Loss: 0.1831, Val Loss: 0.5433, Val Accuracy: 0.7571\n",
            "Epoch: 12, Train Loss: 0.1459, Val Loss: 0.5873, Val Accuracy: 0.7408\n",
            "Epoch: 13, Train Loss: 0.1188, Val Loss: 0.5486, Val Accuracy: 0.8064\n",
            "Epoch: 14, Train Loss: 0.0547, Val Loss: 0.6478, Val Accuracy: 0.8083\n",
            "Epoch: 15, Train Loss: 0.0310, Val Loss: 0.6702, Val Accuracy: 0.7939\n",
            "LSTM Run 5: Accuracy on validation set: 0.7809, Average loss on validation set: 0.7398\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2594b977b5234adea4f798bb17f1c2dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁█▆▁▄</td></tr><tr><td>avg_loss</td><td>▂▁▁██</td></tr><tr><td>run</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>▇▇▅▄▃▃▃▂▇▅▅▄▃▄▃▂▇▅▄▄▆▃▃▂▇▅▄▃▃▂▂▁█▆▅▄▃▂▂▁</td></tr><tr><td>val_loss</td><td>▃▂▂▂▁▁▁▁▃▂▂▁▁▂▁▂█▃▁▁▂▁▂▂▃▂▁▁▂▂▂▃▃▃▂▁▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.78093</td></tr><tr><td>avg_loss</td><td>0.73984</td></tr><tr><td>run</td><td>5</td></tr><tr><td>train_loss</td><td>0.03099</td></tr><tr><td>val_loss</td><td>0.67021</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">LSTM_Experiment</strong> at: <a href='https://wandb.ai/prisha/hyperparameter-tuning_LSTM/runs/zknl8ox1/workspace' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_LSTM/runs/zknl8ox1/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240326_173206-zknl8ox1/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Wandb for the RNN experiment\n",
        "wandb.init(project=\"hyperparameter-tuning_RNN\", name=\"RNN_Experiment\")\n",
        "\n",
        "# Define hyperparameters for the RNN\n",
        "config_rnn = {\"embedding_dim\": 64, \"hidden_dim\": 128, \"batch_size\": 100}\n",
        "\n",
        "# Create the RNN model with specified hyperparameters\n",
        "model_rnn = RNNClassifier(config_rnn[\"embedding_dim\"], config_rnn[\"hidden_dim\"], vocab_size=5000).to(device)\n",
        "\n",
        "# Define optimizer and loss function for RNN\n",
        "optimizer_rnn = torch.optim.Adam(model_rnn.parameters())\n",
        "loss_fn_rnn = torch.nn.BCELoss()\n",
        "\n",
        "# DataLoader for RNN\n",
        "train_sample_dl_rnn = torch.utils.data.DataLoader(train_sample_ds, batch_size=config_rnn[\"batch_size\"])\n",
        "test_sample_dl_rnn = torch.utils.data.DataLoader(test_sample_ds, batch_size=config_rnn[\"batch_size\"])\n",
        "val_sample_dl_rnn = torch.utils.data.DataLoader(val_sample_ds, batch_size=config_rnn[\"batch_size\"])\n",
        "\n",
        "# Train the RNN model\n",
        "train(model_rnn, train_sample_dl_rnn, val_sample_dl_rnn, 15, optimizer_rnn, loss_fn_rnn, device)\n",
        "\n",
        "# Evaluate the RNN model on the test set\n",
        "accuracy_rnn, avg_loss_rnn = evaluate(model_rnn, test_sample_dl_rnn, loss_fn_rnn, device)\n",
        "\n",
        "# Log metrics using Wandb\n",
        "print(f\"RNN: Accuracy on test set: {accuracy_rnn:.4f}, Average loss on test set: {avg_loss_rnn:.4f}\")\n",
        "wandb.log({\"accuracy_rnn\": accuracy_rnn, \"avg_loss_rnn\": avg_loss_rnn})\n",
        "\n",
        "# Finish Wandb run for RNN\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614,
          "referenced_widgets": [
            "afb6ec90d91c496d9360fd8eca128beb",
            "eacb45c17e1846f9a45a8370e1269a59",
            "9bc65065bb3b439abb536ea727702111",
            "f73d7f5cd5e3417c92cfbd8325ed6a80",
            "07502882222e4dcf901c9158e849f2f4",
            "0f382381d4214758a34ab62c954e4c89",
            "9929bac6803749f6898cfc50fd6f039b",
            "d9f78ac8bbde40aaabf9ed8293ef7e2c"
          ]
        },
        "id": "sj3fhAAHvvhw",
        "outputId": "3563b8a7-493e-4ce7-a720-cfbfebc5486b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240326_175034-yq9ibw1i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prisha/hyperparameter-tuning_RNN/runs/yq9ibw1i/workspace' target=\"_blank\">RNN_Experiment</a></strong> to <a href='https://wandb.ai/prisha/hyperparameter-tuning_RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prisha/hyperparameter-tuning_RNN' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_RNN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prisha/hyperparameter-tuning_RNN/runs/yq9ibw1i/workspace' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_RNN/runs/yq9ibw1i/workspace</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 0.6934, Val Loss: 0.6929, Val Accuracy: 0.5063\n",
            "Epoch: 2, Train Loss: 0.6947, Val Loss: 0.6930, Val Accuracy: 0.5063\n",
            "Epoch: 3, Train Loss: 0.6929, Val Loss: 0.6930, Val Accuracy: 0.5063\n",
            "Epoch: 4, Train Loss: 0.6929, Val Loss: 0.6931, Val Accuracy: 0.5058\n",
            "Epoch: 5, Train Loss: 0.6928, Val Loss: 0.6931, Val Accuracy: 0.5063\n",
            "Epoch: 6, Train Loss: 0.6927, Val Loss: 0.6932, Val Accuracy: 0.5058\n",
            "Epoch: 7, Train Loss: 0.6925, Val Loss: 0.6934, Val Accuracy: 0.5058\n",
            "Epoch: 8, Train Loss: 0.6924, Val Loss: 0.6934, Val Accuracy: 0.5067\n",
            "Epoch: 9, Train Loss: 0.6923, Val Loss: 0.6932, Val Accuracy: 0.5072\n",
            "Epoch: 10, Train Loss: 0.6922, Val Loss: 0.6935, Val Accuracy: 0.5058\n",
            "Epoch: 11, Train Loss: 0.6920, Val Loss: 0.6937, Val Accuracy: 0.5063\n",
            "Epoch: 12, Train Loss: 0.6920, Val Loss: 0.6937, Val Accuracy: 0.5063\n",
            "Epoch: 13, Train Loss: 0.6924, Val Loss: 0.6937, Val Accuracy: 0.5058\n",
            "Epoch: 14, Train Loss: 0.6921, Val Loss: 0.6941, Val Accuracy: 0.5058\n",
            "Epoch: 15, Train Loss: 0.6922, Val Loss: 0.6942, Val Accuracy: 0.5054\n",
            "RNN: Accuracy on test set: 0.4953, Average loss on test set: 0.6941\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afb6ec90d91c496d9360fd8eca128beb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_rnn</td><td>▁</td></tr><tr><td>avg_loss_rnn</td><td>▁</td></tr><tr><td>train_loss</td><td>▅█▃▃▃▃▂▂▂▂▁▁▂▁▂</td></tr><tr><td>val_loss</td><td>▁▂▂▂▂▃▄▄▃▄▅▅▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_rnn</td><td>0.49533</td></tr><tr><td>avg_loss_rnn</td><td>0.69406</td></tr><tr><td>train_loss</td><td>0.69217</td></tr><tr><td>val_loss</td><td>0.69423</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RNN_Experiment</strong> at: <a href='https://wandb.ai/prisha/hyperparameter-tuning_RNN/runs/yq9ibw1i/workspace' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_RNN/runs/yq9ibw1i/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240326_175034-yq9ibw1i/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "wandb.init(project=\"hyperparameter-tuning_rnn_2\", name=\"RNN_Experiment_2\")\n",
        "\n",
        "class RNNLastOutput(nn.Module):\n",
        "    \"\"\" RNNLastOutput class for initializing the layers for the RNN model\n",
        "    that only picks the last output of the RNN layer.\n",
        "\n",
        "    Attributes:\n",
        "        embedding_dim (int): Dimensionality of the embedding layer\n",
        "        hidden_dim (int): Dimensionality of the hidden layer(s)\n",
        "        vocab_size (int): Size of the vocabulary used by Bag of Words\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super(RNNLastOutput, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.dense = nn.Linear(hidden_dim, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        lengths = x[:, 0]  # Extract lengths from the input\n",
        "        reviews = x[:, 1:]  # Extract reviews from the input\n",
        "        embeds = self.embedding(reviews)\n",
        "        rnn_out, _ = self.rnn(embeds)\n",
        "        last_output = rnn_out[:, -1, :]  # Select the last time step's output\n",
        "        output = self.dense(last_output)\n",
        "        return self.sig(output.squeeze())\n",
        "\n",
        "class RNNMeanOutput(nn.Module):\n",
        "    \"\"\" RNNMeanOutput class for initializing the layers for the RNN model\n",
        "    that takes the mean of all outputs in the RNN layer.\n",
        "\n",
        "    Attributes:\n",
        "        embedding_dim (int): Dimensionality of the embedding layer\n",
        "        hidden_dim (int): Dimensionality of the hidden layer(s)\n",
        "        vocab_size (int): Size of the vocabulary used by Bag of Words\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super(RNNMeanOutput, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.dense = nn.Linear(hidden_dim, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        lengths = x[:, 0]  # Extract lengths from the input\n",
        "        reviews = x[:, 1:]  # Extract reviews from the input\n",
        "        embeds = self.embedding(reviews)\n",
        "        rnn_out, _ = self.rnn(embeds)\n",
        "        mean_output = torch.mean(rnn_out, dim=1)\n",
        "        output = self.dense(mean_output)\n",
        "        return self.sig(output.squeeze())\n",
        "\n",
        "# Initialize the RNN models\n",
        "model_last_output = RNNLastOutput(embedding_dim=32, hidden_dim=100, vocab_size=5000).to(device)\n",
        "model_mean_output = RNNMeanOutput(embedding_dim=32, hidden_dim=100, vocab_size=5000).to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optimizer = torch.optim.Adam(model_last_output.parameters())\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "# Train and evaluate the RNN model with last output\n",
        "train(model_last_output, train_sample_dl, val_sample_dl, 15, optimizer, loss_fn, device)\n",
        "accuracy_last_output, avg_loss_last_output = evaluate(model_last_output, test_sample_dl, loss_fn, device)\n",
        "print(\"RNN with last output: Accuracy =\", accuracy_last_output, \", Avg Loss =\", avg_loss_last_output)\n",
        "optimizer = torch.optim.Adam(model_mean_output.parameters())\n",
        "\n",
        "# Train and evaluate the RNN model with mean output\n",
        "train(model_mean_output, train_sample_dl, val_sample_dl, 15, optimizer, loss_fn, device)\n",
        "accuracy_mean_output, avg_loss_mean_output = evaluate(model_mean_output, test_sample_dl, loss_fn, device)\n",
        "print(\"RNN with mean output: Accuracy =\", accuracy_mean_output, \", Avg Loss =\", avg_loss_mean_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "5830f40dcb744e7c84ceaa5533d38dbc",
            "33ba4b113c2d4259b6900cee177a6e48",
            "9f6b4494fc0e433bb446127c96807d46",
            "59fdd64c94a74dd792879c964559dcaf",
            "59982aaa859f4f41ad48cf643a135eec",
            "07b27fe805434f1aa92ed0c56f29799b",
            "dc5bf668035d42bd903e23fe2855408f",
            "3ba9272df5e64dee99ea47b62ef1d019"
          ]
        },
        "id": "LHfLJjAtvxik",
        "outputId": "dcb0df14-e04c-44b6-ccb8-0592b87f636b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:vqnukmc7) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5830f40dcb744e7c84ceaa5533d38dbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█████████████████▇▇▇▆▆▅▄▅▅▄▃▂▁</td></tr><tr><td>val_loss</td><td>██████████████████▇▇▆▆▅▄▅▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.40759</td></tr><tr><td>val_loss</td><td>0.43984</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RNN_Experiment_2</strong> at: <a href='https://wandb.ai/prisha/hyperparameter-tuning_rnn_2/runs/vqnukmc7/workspace' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_rnn_2/runs/vqnukmc7/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240326_175050-vqnukmc7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:vqnukmc7). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240326_175134-fvi8gshk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prisha/hyperparameter-tuning_rnn_2/runs/fvi8gshk/workspace' target=\"_blank\">RNN_Experiment_2</a></strong> to <a href='https://wandb.ai/prisha/hyperparameter-tuning_rnn_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prisha/hyperparameter-tuning_rnn_2' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_rnn_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prisha/hyperparameter-tuning_rnn_2/runs/fvi8gshk/workspace' target=\"_blank\">https://wandb.ai/prisha/hyperparameter-tuning_rnn_2/runs/fvi8gshk/workspace</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 0.6941, Val Loss: 0.6927, Val Accuracy: 0.5072\n",
            "Epoch: 2, Train Loss: 0.6936, Val Loss: 0.6928, Val Accuracy: 0.5067\n",
            "Epoch: 3, Train Loss: 0.6931, Val Loss: 0.6928, Val Accuracy: 0.5067\n",
            "Epoch: 4, Train Loss: 0.6929, Val Loss: 0.6927, Val Accuracy: 0.5067\n",
            "Epoch: 5, Train Loss: 0.6927, Val Loss: 0.6925, Val Accuracy: 0.5077\n",
            "Epoch: 6, Train Loss: 0.6931, Val Loss: 0.6928, Val Accuracy: 0.5072\n",
            "Epoch: 7, Train Loss: 0.6928, Val Loss: 0.6928, Val Accuracy: 0.5067\n",
            "Epoch: 8, Train Loss: 0.6929, Val Loss: 0.6928, Val Accuracy: 0.5063\n",
            "Epoch: 9, Train Loss: 0.6928, Val Loss: 0.6929, Val Accuracy: 0.5067\n",
            "Epoch: 10, Train Loss: 0.6928, Val Loss: 0.6929, Val Accuracy: 0.5063\n",
            "Epoch: 11, Train Loss: 0.6927, Val Loss: 0.6930, Val Accuracy: 0.5063\n",
            "Epoch: 12, Train Loss: 0.6927, Val Loss: 0.6930, Val Accuracy: 0.5063\n",
            "Epoch: 13, Train Loss: 0.6926, Val Loss: 0.6931, Val Accuracy: 0.5063\n",
            "Epoch: 14, Train Loss: 0.6925, Val Loss: 0.6932, Val Accuracy: 0.5058\n",
            "Epoch: 15, Train Loss: 0.6924, Val Loss: 0.6933, Val Accuracy: 0.5054\n",
            "RNN with last output: Accuracy = 0.49571020019065776 , Avg Loss = 0.6934154686473665\n",
            "Epoch: 1, Train Loss: 0.6926, Val Loss: 0.6903, Val Accuracy: 0.5072\n",
            "Epoch: 2, Train Loss: 0.6894, Val Loss: 0.6851, Val Accuracy: 0.5812\n",
            "Epoch: 3, Train Loss: 0.6807, Val Loss: 0.6744, Val Accuracy: 0.6180\n",
            "Epoch: 4, Train Loss: 0.6674, Val Loss: 0.6551, Val Accuracy: 0.6426\n",
            "Epoch: 5, Train Loss: 0.6473, Val Loss: 0.6454, Val Accuracy: 0.6482\n",
            "Epoch: 6, Train Loss: 0.6156, Val Loss: 1.2907, Val Accuracy: 0.6501\n",
            "Epoch: 7, Train Loss: 0.6059, Val Loss: 0.5652, Val Accuracy: 0.7692\n",
            "Epoch: 8, Train Loss: 0.5696, Val Loss: 0.5916, Val Accuracy: 0.7650\n",
            "Epoch: 9, Train Loss: 0.5729, Val Loss: 0.5608, Val Accuracy: 0.7725\n",
            "Epoch: 10, Train Loss: 0.5154, Val Loss: 0.4822, Val Accuracy: 0.7790\n",
            "Epoch: 11, Train Loss: 0.5654, Val Loss: 0.5765, Val Accuracy: 0.7915\n",
            "Epoch: 12, Train Loss: 0.5599, Val Loss: 0.5618, Val Accuracy: 0.7934\n",
            "Epoch: 13, Train Loss: 0.5350, Val Loss: 0.5341, Val Accuracy: 0.8022\n",
            "Epoch: 14, Train Loss: 0.5020, Val Loss: 0.5034, Val Accuracy: 0.8074\n",
            "Epoch: 15, Train Loss: 0.4666, Val Loss: 0.4713, Val Accuracy: 0.8134\n",
            "RNN with mean output: Accuracy = 0.7886558627264061 , Avg Loss = 0.4947675196897416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Outperforms RNN\n",
        "LSTM (Long Short-Term Memory) performed better than the basic RNN (Recurrent Neural Network) architecture due to its ability to mitigate the vanishing gradient problem and better capture long-range dependencies in sequential data. In sentiment analysis of movie reviews, where understanding the context and sentiment over longer sequences is crucial."
      ],
      "metadata": {
        "id": "G-POCnVz12GE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When experimenting with different methods of handling RNN outputs, it was observed that taking the mean of all outputs in the RNN layer yielded better results compared to considering only the last output. This improvement in accuracy, reaching approximately 70%, can be explained by the fact that averaging the outputs helps in aggregating information from all time steps, providing a more comprehensive representation of the input sequence and reducing the impact of noisy or irrelevant information"
      ],
      "metadata": {
        "id": "cU31AW4f1-gs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incorporating Stemming/Lemmatization\n",
        "Incorporating stemming or lemmatization during text preprocessing resulted in a more compact and normalized vocabulary, reducing the number of unique words and normalizing variations of the same word. This process aids in generalization by treating different forms of a word as identical, thus improving the model's ability to recognize patterns and sentiments across various word forms and enhancing overall performance"
      ],
      "metadata": {
        "id": "ssjr4H7i2Cnu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2owAY3Fz1-v4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}