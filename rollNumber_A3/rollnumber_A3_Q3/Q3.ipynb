{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltEQ-sUobK7N",
        "outputId": "04f1396c-594d-41a0-c144-ae2a221fe960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-18 18:03:10--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘../data/aclImdb_v1.tar.gz’\n",
            "\n",
            "../data/aclImdb_v1. 100%[===================>]  80.23M  17.9MB/s    in 6.8s    \n",
            "\n",
            "2024-03-18 18:03:17 (11.7 MB/s) - ‘../data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir ../data\n",
        "!wget -O ../data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -zxf ../data/aclImdb_v1.tar.gz -C ../data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def read_imdb_data(data_dir='../data/aclImdb'):\n",
        "    data = {}\n",
        "    labels = {}\n",
        "\n",
        "    for data_type in ['train', 'test']:\n",
        "        data[data_type] = {}\n",
        "        labels[data_type] = {}\n",
        "\n",
        "        for sentiment in ['pos', 'neg']:\n",
        "            data[data_type][sentiment] = []\n",
        "            labels[data_type][sentiment] = []\n",
        "\n",
        "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
        "            files = glob.glob(path)\n",
        "\n",
        "            for f in files:\n",
        "                with open(f) as review:\n",
        "                    data[data_type][sentiment].append(review.read())\n",
        "                    # Here we represent a positive review by '1' and a negative review by '0'\n",
        "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
        "\n",
        "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
        "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
        "\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "Vi3llbw0b9uo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = read_imdb_data()\n",
        "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
        "            len(data['train']['pos']), len(data['train']['neg']),\n",
        "            len(data['test']['pos']), len(data['test']['neg'])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MdvyAZ1cZXb",
        "outputId": "5fe2be4e-6b93-4e0b-98cc-b19e55582d45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "def prepare_imdb_data(data, labels):\n",
        "    #Combine positive and negative reviews and labels\n",
        "    data_train = data['train']['pos'] + data['train']['neg']\n",
        "    data_test = data['test']['pos'] + data['test']['neg']\n",
        "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
        "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
        "\n",
        "    #Shuffle reviews and corresponding labels within training and test sets\n",
        "    data_train, labels_train = shuffle(data_train, labels_train)\n",
        "    data_test, labels_test = shuffle(data_test, labels_test)\n",
        "\n",
        "    # Return a unified training data, test data, training labels, test labels\n",
        "    return data_train, data_test, labels_train, labels_test"
      ],
      "metadata": {
        "id": "WP91n_jbcblo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
        "print(len(train_X))\n",
        "print(len(train_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B-3MZJsdBXV",
        "outputId": "03116667-d6df-4c33-b09f-9a8524f49e60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n",
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step in processing the reviews is to make sure that any html tags that appear should be removed. In addition we wish to tokenize our input, that way words such as entertained and entertaining are considered the same with regard to sentiment analysis."
      ],
      "metadata": {
        "id": "XdEj0NmNd0xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def review_to_words(review):\n",
        "    nltk.download(\"stopwords\", quiet=True)\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
        "    words = text.split() # Split string into words\n",
        "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
        "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
        "\n",
        "    return words"
      ],
      "metadata": {
        "id": "ZGE14NCJdE9c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[100])\n",
        "review_to_words(train_X[100])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkh7ihayerPG",
        "outputId": "07590b8b-8299-43fa-ee3d-ff017633693d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is one of quite a few cartoons with Bugs Bunny and Marvin the Martian - and a space dog called K-9 is included as well. This Looney Tunes episode is very funny, has reasonably good cartoon animation (Marvin's animation is very well done) and the plot is well done. The end is rather weird, so be prepared for it, it is slightly boring. <br /><br />In this episode, Marvin the Martian has been sent to earth to capture an earth creature and bring it back to Mars. With his trusty dog K-9, Marvin sets out and soon finds the tracks of no other rabbit but Bugs Bunny! He greets them with treats, thinking they are trick or treaters in their costumes. Little does he realise they are preparing themselves to take this rabbit to Mars...<br /><br />I recommend this episode to anyone who likes Bugs Bunny, Marvin the Martian and Looney Tunes in general. As far as the beginning and the middle of the episode are concerned, you are likely to like this. Enjoy \"Hasty Hare\"! :-)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one',\n",
              " 'quit',\n",
              " 'cartoon',\n",
              " 'bug',\n",
              " 'bunni',\n",
              " 'marvin',\n",
              " 'martian',\n",
              " 'space',\n",
              " 'dog',\n",
              " 'call',\n",
              " 'k',\n",
              " '9',\n",
              " 'includ',\n",
              " 'well',\n",
              " 'looney',\n",
              " 'tune',\n",
              " 'episod',\n",
              " 'funni',\n",
              " 'reason',\n",
              " 'good',\n",
              " 'cartoon',\n",
              " 'anim',\n",
              " 'marvin',\n",
              " 'anim',\n",
              " 'well',\n",
              " 'done',\n",
              " 'plot',\n",
              " 'well',\n",
              " 'done',\n",
              " 'end',\n",
              " 'rather',\n",
              " 'weird',\n",
              " 'prepar',\n",
              " 'slightli',\n",
              " 'bore',\n",
              " 'episod',\n",
              " 'marvin',\n",
              " 'martian',\n",
              " 'sent',\n",
              " 'earth',\n",
              " 'captur',\n",
              " 'earth',\n",
              " 'creatur',\n",
              " 'bring',\n",
              " 'back',\n",
              " 'mar',\n",
              " 'trusti',\n",
              " 'dog',\n",
              " 'k',\n",
              " '9',\n",
              " 'marvin',\n",
              " 'set',\n",
              " 'soon',\n",
              " 'find',\n",
              " 'track',\n",
              " 'rabbit',\n",
              " 'bug',\n",
              " 'bunni',\n",
              " 'greet',\n",
              " 'treat',\n",
              " 'think',\n",
              " 'trick',\n",
              " 'treater',\n",
              " 'costum',\n",
              " 'littl',\n",
              " 'realis',\n",
              " 'prepar',\n",
              " 'take',\n",
              " 'rabbit',\n",
              " 'mar',\n",
              " 'recommend',\n",
              " 'episod',\n",
              " 'anyon',\n",
              " 'like',\n",
              " 'bug',\n",
              " 'bunni',\n",
              " 'marvin',\n",
              " 'martian',\n",
              " 'looney',\n",
              " 'tune',\n",
              " 'gener',\n",
              " 'far',\n",
              " 'begin',\n",
              " 'middl',\n",
              " 'episod',\n",
              " 'concern',\n",
              " 'like',\n",
              " 'like',\n",
              " 'enjoy',\n",
              " 'hasti',\n",
              " 'hare']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "cache_dir = os.path.join(\"../cache\", \"sentiment_analysis\")  # where to store cache files\n",
        "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
        "\n",
        "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
        "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
        "    \"\"\"Convert each review to words; read from cache if available.\"\"\"\n",
        "\n",
        "    # If cache_file is not None, try to read from it first\n",
        "    cache_data = None\n",
        "    if cache_file is not None:\n",
        "        try:\n",
        "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
        "                cache_data = pickle.load(f)\n",
        "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
        "        except:\n",
        "            pass  # unable to read from cache, but that's okay\n",
        "\n",
        "    # If cache is missing, then do the heavy lifting\n",
        "    if cache_data is None:\n",
        "        # Preprocess training and test data to obtain words for each review\n",
        "        #words_train = list(map(review_to_words, data_train))\n",
        "        #words_test = list(map(review_to_words, data_test))\n",
        "        words_train = [review_to_words(review) for review in data_train]\n",
        "        words_test = [review_to_words(review) for review in data_test]\n",
        "\n",
        "        # Write to cache file for future runs\n",
        "        if cache_file is not None:\n",
        "            cache_data = dict(words_train=words_train, words_test=words_test,\n",
        "                              labels_train=labels_train, labels_test=labels_test)\n",
        "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
        "                pickle.dump(cache_data, f)\n",
        "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
        "    else:\n",
        "        # Unpack data loaded from cache file\n",
        "        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
        "                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
        "\n",
        "    return words_train, words_test, labels_train, labels_test"
      ],
      "metadata": {
        "id": "luRLaCMgeyyP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X, train_y, test_y = preprocess_data(train_X, test_X, train_y, test_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MaPkbAxwXJR",
        "outputId": "40d4381e-7e32-43b9-d6ac-2d06fead0301"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-50fb9c11b9e9>:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote preprocessed data to cache file: preprocessed_data.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we will be using a recurrent neural network, it will be convenient if the length of each review is the same. To do this, we will fix a size for our reviews and then pad short reviews with the category 'no word' (which we will label 0) and truncate long reviews. Basically in the dictionary the one with the most higher rank is the one that occurs most frequently. You dont care for the first two these are no words"
      ],
      "metadata": {
        "id": "__DN0F4syJkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7bgt70phy7sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def build_dict(data, vocab_size = 5000):\n",
        "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
        "\n",
        "    # DONE: Determine how often each word appears in `data`. Note that `data` is a list of sentences and that a\n",
        "    #       sentence is a list of words.\n",
        "\n",
        "    # A dict storing the words that appear in the reviews along with how often they occur\n",
        "    word_count = {}\n",
        "\n",
        "    for sentence in data:\n",
        "        for word in sentence:\n",
        "            if word in word_count:\n",
        "                word_count[word] += 1\n",
        "            else:\n",
        "                word_count[word] = 1\n",
        "\n",
        "    # DONE: Sort the words found in `data` so that sorted_words[0] is the most frequently appearing word and\n",
        "    #       sorted_words[-1] is the least frequently appearing word.\n",
        "\n",
        "    sorted_words = sorted(word_count, key=word_count.get, reverse=True)\n",
        "    #print(sorted_words[0])\n",
        "    #print(sorted_words[-1])\n",
        "\n",
        "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
        "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): # The -2 is so that we save room for the 'no word'\n",
        "        word_dict[word] = idx + 2                              # 'infrequent' labels\n",
        "\n",
        "    return word_dict"
      ],
      "metadata": {
        "id": "MPbg30bJwa_U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict = build_dict(train_X)\n",
        "print(list(word_dict.keys())[0:5])\n",
        "data_dir = '../data/pytorch' # The folder we will use for storing data\n",
        "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
        "    pickle.dump(word_dict, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4vliUPYy6g5",
        "outputId": "22d85ed4-1d84-447d-aa6f-f9fa9bf0ab40"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['movi', 'film', 'one', 'like', 'time']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our word dictionary which allows us to transform the words appearing in the reviews into integers, it is time to make use of it and convert our reviews to their integer sequence representation, making sure to pad or truncate to a fixed length, which in our case is 500."
      ],
      "metadata": {
        "id": "5FbCg7lP0kM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_and_pad(word_dict, sentence, pad=500):\n",
        "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
        "    INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
        "\n",
        "    working_sentence = [NOWORD] * pad\n",
        "\n",
        "    for word_index, word in enumerate(sentence[:pad]):\n",
        "        if word in word_dict:\n",
        "            working_sentence[word_index] = word_dict[word]\n",
        "        else:\n",
        "            working_sentence[word_index] = INFREQ\n",
        "\n",
        "    return working_sentence, min(len(sentence), pad)"
      ],
      "metadata": {
        "id": "FRMKuC5R1SGU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_and_pad_data(word_dict, data, pad=500):\n",
        "    result = []\n",
        "    lengths = []\n",
        "\n",
        "    for sentence in data:\n",
        "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
        "        result.append(converted)\n",
        "        lengths.append(leng)\n",
        "\n",
        "    return np.array(result), np.array(lengths)"
      ],
      "metadata": {
        "id": "6Ze7Qf851PzD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
        "test_X, test_X_len = convert_and_pad_data(word_dict, test_X)\n"
      ],
      "metadata": {
        "id": "-76tjVYQ0rgd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '../data/pytorch' # The folder we will use for storing data\n",
        "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
        "    pickle.dump(word_dict, f)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1) \\\n",
        "        .to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
      ],
      "metadata": {
        "id": "ymhimb1v1bK9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[0])\n",
        "print(train_X_len[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXnpy_sr2BMI",
        "outputId": "1ee2b8c6-97ae-4231-9a83-c6f1a5b6fee1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 660 1278    1 1880  347  601    4  329  358  306 2617  682  184  347\n",
            " 3507  841  445    6  814  213  197    1  101  797   20    4    1  284\n",
            "  373 1881  163 3533    3  640  280    1  245  287  240    1    1   60\n",
            "  410   49   52  338  181   15    5   11   79    3    1    4   54 3508\n",
            "    1 1615    1    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0]\n",
            "59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    \"\"\" LSTMClassifier class for initializing the layers for the simple\n",
        "    recurrent neural network model (RNN) used for Sentiment Analysis of\n",
        "    IMDB reviews.\n",
        "\n",
        "    Attributes:\n",
        "        embedding_dim (int) dimensionality of the embedding layer\n",
        "        hidden_dim (int) dimensionality of the hidden layer(s)\n",
        "        vocab_size (int) size of the vocabulary used by Bag of Words\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "        self.word_dict = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.t()\n",
        "        lengths = x[0,:]\n",
        "        reviews = x[1:,:]\n",
        "        embeds = self.embedding(reviews)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        out = self.dense(lstm_out)\n",
        "        out = out[lengths - 1, range(len(lengths))]\n",
        "        return self.sig(out.squeeze())"
      ],
      "metadata": {
        "id": "B8GPHB2j3DKR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "# Read in only the first 250 rows\n",
        "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None)\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "train_sample_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
        "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
        "# Build the dataloader\n",
        "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=100)"
      ],
      "metadata": {
        "id": "IQ-VC_tk5mGD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            batch_X, batch_y = batch\n",
        "\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            # DONE: Complete this train method to train the model provided.\n",
        "            optimizer.zero_grad()\n",
        "            output = model.forward(batch_X)\n",
        "            loss = loss_fn(output, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.data.item()\n",
        "        print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss / len(train_loader)))"
      ],
      "metadata": {
        "id": "a9YakS7Y6GGW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LSTMClassifier(32, 100, 5000).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "train(model, train_sample_dl, 15, optimizer, loss_fn, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk1Ex8gT6NBg",
        "outputId": "5faac2b3-34b5-4087-99cb-18f50bd775ff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.6284457104206085\n",
            "Epoch: 2, Loss: 0.511864448428154\n",
            "Epoch: 3, Loss: 0.3934649955034256\n",
            "Epoch: 4, Loss: 0.33832233828306196\n",
            "Epoch: 5, Loss: 0.302040314078331\n",
            "Epoch: 6, Loss: 0.28056073033809664\n",
            "Epoch: 7, Loss: 0.28352860754728315\n",
            "Epoch: 8, Loss: 0.23945282605290413\n",
            "Epoch: 9, Loss: 0.23098776400089263\n",
            "Epoch: 10, Loss: 0.24441413468122483\n",
            "Epoch: 11, Loss: 0.21906791719794275\n",
            "Epoch: 12, Loss: 0.20859959319233895\n",
            "Epoch: 13, Loss: 0.17155315992236136\n",
            "Epoch: 14, Loss: 0.1639059560596943\n",
            "Epoch: 15, Loss: 0.14581003014743327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '../data/pytorch'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Specify the file path where you want to save the model within the data_dir\n",
        "model_path = os.path.join(data_dir, 'trained_model.pth')\n",
        "\n",
        "# Save the model state dictionary\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "print(\"Model saved successfully at:\", model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccH5tf4oL1cU",
        "outputId": "5dfcce9f-55e0-403f-821c-2c1db4a1817c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully at: ../data/pytorch/trained_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([pd.DataFrame(test_y), pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1) \\\n",
        "        .to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)"
      ],
      "metadata": {
        "id": "98SRoP8_6YaE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in only the first 250 rows\n",
        "test_sample = pd.read_csv(os.path.join(data_dir, 'test.csv'), header=None, names=None)\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "test_sample_y = torch.from_numpy(test_sample[[0]].values).float().squeeze()\n",
        "test_sample_X = torch.from_numpy(test_sample.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "test_sample_ds = torch.utils.data.TensorDataset(test_sample_X, test_sample_y)\n",
        "# Build the dataloader\n",
        "test_sample_dl = torch.utils.data.DataLoader(test_sample_ds, batch_size=100)"
      ],
      "metadata": {
        "id": "-9tn62MV88fO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Function to evaluate the model on a given dataset.\n",
        "\n",
        "    Args:\n",
        "    - model: the PyTorch model to evaluate\n",
        "    - dataloader: DataLoader object for the dataset\n",
        "    - loss_fn: loss function used for training\n",
        "    - device: device to run the evaluation on (e.g., \"cpu\" or \"cuda\")\n",
        "\n",
        "    Returns:\n",
        "    - accuracy: accuracy of the model on the dataset\n",
        "    - loss: average loss on the dataset\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during evaluation\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Compute accuracy\n",
        "            predicted = torch.round(outputs)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "\n",
        "    return accuracy, avg_loss\n"
      ],
      "metadata": {
        "id": "r8Qa246-9sdY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, avg_loss = evaluate(model, test_sample_dl, loss_fn, device)\n",
        "print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
        "print(f\"Average loss on test set: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCi40N3a-kid",
        "outputId": "e23032af-a854-4d3a-f273-65982413186e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.8629\n",
            "Average loss on test set: 0.4438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jntgERVM-mwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}