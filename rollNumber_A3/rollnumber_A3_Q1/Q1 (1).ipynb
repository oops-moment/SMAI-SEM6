{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVYaSaJXzzsC"
      },
      "source": [
        "**NN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Vjh8L8Kxsmk-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define training function\n",
        "def train_model(model, train_loader, val_loader,optimizer, epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            images, labels = batch[0].to(device), batch[1].to(device)  # Move batch to device\n",
        "            # make the gradients as zero before you start with this batch\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            # feed the outputs predicted by the model to the criterion to calculate the loss function and then backpropagate\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            # update the weights accordingly\n",
        "            optimizer.step()\n",
        "\n",
        "        val_loss, val_acc = evaluate(model, val_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move batch to device\n",
        "            outputs = model(images)\n",
        "            loss = F.cross_entropy(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            # basically one out of 10 with the highest probability would correspond to output of that\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    average_loss = total_loss / len(val_loader)\n",
        "    return average_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1,hidden_size2,hidden_size3, output_size):\n",
        "        super(CIFAR10MLP, self).__init__()\n",
        "        # define the first and second fully connected layer and the output layer as well\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2,hidden_size3)\n",
        "        self.fc4 = nn.Linear(hidden_size3, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # Apply the relu activation function for first and second layer only\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x= F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jDwoGN0qskb3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw7K15GBzHKM",
        "outputId": "0fe6c83b-23c6-433b-a22d-53d9b51bac68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load CIFAR-10 dataset\n",
        "dataset = CIFAR10(root='data/', download=True, transform=ToTensor())\n",
        "test_dataset = CIFAR10(root='data/', train=False, transform=ToTensor())\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gypB-MKWkafq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4a18a1-6c1f-4b30-e02c-19720b87451f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Val Loss: 1.7827, Val Acc: 0.3610\n",
            "Epoch [2/30], Val Loss: 1.6489, Val Acc: 0.4136\n",
            "Epoch [3/30], Val Loss: 1.6399, Val Acc: 0.4228\n",
            "Epoch [4/30], Val Loss: 1.5613, Val Acc: 0.4458\n",
            "Epoch [5/30], Val Loss: 1.5252, Val Acc: 0.4584\n",
            "Epoch [6/30], Val Loss: 1.5089, Val Acc: 0.4598\n",
            "Epoch [7/30], Val Loss: 1.5289, Val Acc: 0.4510\n",
            "Epoch [8/30], Val Loss: 1.5132, Val Acc: 0.4666\n",
            "Epoch [9/30], Val Loss: 1.4510, Val Acc: 0.4860\n",
            "Epoch [10/30], Val Loss: 1.4650, Val Acc: 0.4836\n",
            "Epoch [11/30], Val Loss: 1.4154, Val Acc: 0.5050\n",
            "Epoch [12/30], Val Loss: 1.4190, Val Acc: 0.5014\n",
            "Epoch [13/30], Val Loss: 1.4010, Val Acc: 0.5118\n",
            "Epoch [14/30], Val Loss: 1.3880, Val Acc: 0.5120\n",
            "Epoch [15/30], Val Loss: 1.4050, Val Acc: 0.5134\n",
            "Epoch [16/30], Val Loss: 1.4136, Val Acc: 0.5050\n",
            "Epoch [17/30], Val Loss: 1.4019, Val Acc: 0.5202\n",
            "Epoch [18/30], Val Loss: 1.4069, Val Acc: 0.5106\n",
            "Epoch [19/30], Val Loss: 1.4101, Val Acc: 0.5202\n",
            "Epoch [20/30], Val Loss: 1.4135, Val Acc: 0.5248\n",
            "Epoch [21/30], Val Loss: 1.3960, Val Acc: 0.5266\n",
            "Epoch [22/30], Val Loss: 1.4181, Val Acc: 0.5218\n",
            "Epoch [23/30], Val Loss: 1.4180, Val Acc: 0.5242\n",
            "Epoch [24/30], Val Loss: 1.4344, Val Acc: 0.5156\n",
            "Epoch [25/30], Val Loss: 1.4490, Val Acc: 0.5180\n",
            "Epoch [26/30], Val Loss: 1.4704, Val Acc: 0.5234\n",
            "Epoch [27/30], Val Loss: 1.4715, Val Acc: 0.5162\n",
            "Epoch [28/30], Val Loss: 1.4696, Val Acc: 0.5188\n",
            "Epoch [29/30], Val Loss: 1.4976, Val Acc: 0.5162\n",
            "Epoch [30/30], Val Loss: 1.5327, Val Acc: 0.5128\n",
            "Test Accuracy: 0.5094\n"
          ]
        }
      ],
      "source": [
        "# Model parameters\n",
        "input_size = 3 * 32 * 32  # 3 channels, 32x32 image size\n",
        "hidden_size1 = 512\n",
        "hidden_size2 = 256\n",
        "hidden_size3 =128\n",
        "output_size = 10\n",
        "\n",
        "# # Initialize and train the model\n",
        "model = CIFAR10MLP(input_size, hidden_size1, hidden_size2,hidden_size3, output_size)\n",
        "model = model.to(device)\n",
        "lr=0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "train_model(model, train_loader, val_loader,optimizer,epochs=30)\n",
        "loss,test_accuracy = evaluate(model, test_loader)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1dqeys1zwAi"
      },
      "source": [
        "**CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVgdFdC9zZB2",
        "outputId": "dd842681-8a3e-48d2-b6ca-27a1e4a6daec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Val Loss: 1.4198, Val Acc: 0.4896\n",
            "Epoch [2/30], Val Loss: 1.2678, Val Acc: 0.5484\n",
            "Epoch [3/30], Val Loss: 1.1408, Val Acc: 0.5984\n",
            "Epoch [4/30], Val Loss: 1.0714, Val Acc: 0.6300\n",
            "Epoch [5/30], Val Loss: 1.0181, Val Acc: 0.6570\n",
            "Epoch [6/30], Val Loss: 0.9613, Val Acc: 0.6760\n",
            "Epoch [7/30], Val Loss: 0.9496, Val Acc: 0.6676\n",
            "Epoch [8/30], Val Loss: 0.9267, Val Acc: 0.6854\n",
            "Epoch [9/30], Val Loss: 0.9175, Val Acc: 0.6956\n",
            "Epoch [10/30], Val Loss: 0.9013, Val Acc: 0.7026\n",
            "Epoch [11/30], Val Loss: 0.9070, Val Acc: 0.7030\n",
            "Epoch [12/30], Val Loss: 0.8875, Val Acc: 0.7152\n",
            "Epoch [13/30], Val Loss: 0.9644, Val Acc: 0.6992\n",
            "Epoch [14/30], Val Loss: 0.8992, Val Acc: 0.7200\n",
            "Epoch [15/30], Val Loss: 0.9586, Val Acc: 0.7130\n",
            "Epoch [16/30], Val Loss: 0.9999, Val Acc: 0.7166\n",
            "Epoch [17/30], Val Loss: 1.0997, Val Acc: 0.7136\n",
            "Epoch [18/30], Val Loss: 1.1292, Val Acc: 0.7152\n",
            "Epoch [19/30], Val Loss: 1.2220, Val Acc: 0.7210\n",
            "Epoch [20/30], Val Loss: 1.3143, Val Acc: 0.7146\n",
            "Epoch [21/30], Val Loss: 1.4042, Val Acc: 0.7092\n",
            "Epoch [22/30], Val Loss: 1.4653, Val Acc: 0.7126\n",
            "Epoch [23/30], Val Loss: 1.6560, Val Acc: 0.7026\n",
            "Epoch [24/30], Val Loss: 1.6605, Val Acc: 0.7094\n",
            "Epoch [25/30], Val Loss: 1.6622, Val Acc: 0.7126\n",
            "Epoch [26/30], Val Loss: 1.7888, Val Acc: 0.7106\n",
            "Epoch [27/30], Val Loss: 1.8634, Val Acc: 0.7104\n",
            "Epoch [28/30], Val Loss: 1.9946, Val Acc: 0.7126\n",
            "Epoch [29/30], Val Loss: 1.8773, Val Acc: 0.7128\n",
            "Epoch [30/30], Val Loss: 1.9828, Val Acc: 0.7176\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CIFAR10CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10CNN, self).__init__()\n",
        "        # convolutional layer (sees 32x32x3 image tensor)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        # convolutional layer (sees 16x16x16 tensor)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        # convolutional layer (sees 8x8x32 tensor)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        # linear layer (64 * 4 * 4 -> 500)\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
        "        # linear layer (500 -> 10)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.pool3(F.relu(self.conv3(x)))\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 64 * 4 * 4)\n",
        "        # add dropout layer\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# # Initialize and train the model\n",
        "model1 = CIFAR10CNN()\n",
        "model1 = model1.to(device)\n",
        "lr=0.001\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=lr)\n",
        "train_model(model1, train_loader, val_loader,optimizer,epochs=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGDJj1IWAEco",
        "outputId": "683c3e61-04df-4657-b5e5-7501cdabfc02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7228\n"
          ]
        }
      ],
      "source": [
        "loss1,test_accuracy1 = evaluate(model1, test_loader)\n",
        "print(f\"Test Accuracy: {test_accuracy1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFe4dM-rDXT2"
      },
      "source": [
        "**VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaEh38G6Vto2",
        "outputId": "f0846d42-c68a-4375-ab1a-3a5be51aad87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Val Loss: 1.1002, Val Acc: 0.6150\n",
            "Epoch [2/30], Val Loss: 1.0139, Val Acc: 0.6518\n",
            "Epoch [3/30], Val Loss: 0.9501, Val Acc: 0.6650\n",
            "Epoch [4/30], Val Loss: 0.9117, Val Acc: 0.6822\n",
            "Epoch [5/30], Val Loss: 0.8914, Val Acc: 0.6906\n",
            "Epoch [6/30], Val Loss: 0.8760, Val Acc: 0.6964\n",
            "Epoch [7/30], Val Loss: 0.8586, Val Acc: 0.7018\n",
            "Epoch [8/30], Val Loss: 0.8559, Val Acc: 0.7022\n",
            "Epoch [9/30], Val Loss: 0.8480, Val Acc: 0.7024\n",
            "Epoch [10/30], Val Loss: 0.8390, Val Acc: 0.7108\n",
            "Epoch [11/30], Val Loss: 0.8279, Val Acc: 0.7122\n",
            "Epoch [12/30], Val Loss: 0.8215, Val Acc: 0.7160\n",
            "Epoch [13/30], Val Loss: 0.8114, Val Acc: 0.7188\n",
            "Epoch [14/30], Val Loss: 0.8337, Val Acc: 0.7106\n",
            "Epoch [15/30], Val Loss: 0.8306, Val Acc: 0.7110\n",
            "Epoch [16/30], Val Loss: 0.8205, Val Acc: 0.7150\n",
            "Epoch [17/30], Val Loss: 0.8064, Val Acc: 0.7274\n",
            "Epoch [18/30], Val Loss: 0.8048, Val Acc: 0.7252\n",
            "Epoch [19/30], Val Loss: 0.8330, Val Acc: 0.7180\n",
            "Epoch [20/30], Val Loss: 0.8198, Val Acc: 0.7170\n",
            "Epoch [21/30], Val Loss: 0.8205, Val Acc: 0.7238\n",
            "Epoch [22/30], Val Loss: 0.8206, Val Acc: 0.7260\n",
            "Epoch [23/30], Val Loss: 0.8193, Val Acc: 0.7200\n",
            "Epoch [24/30], Val Loss: 0.8278, Val Acc: 0.7164\n",
            "Epoch [25/30], Val Loss: 0.8476, Val Acc: 0.7148\n",
            "Epoch [26/30], Val Loss: 0.8339, Val Acc: 0.7234\n",
            "Epoch [27/30], Val Loss: 0.8226, Val Acc: 0.7228\n",
            "Epoch [28/30], Val Loss: 0.8251, Val Acc: 0.7274\n",
            "Epoch [29/30], Val Loss: 0.8490, Val Acc: 0.7260\n",
            "Epoch [30/30], Val Loss: 0.8453, Val Acc: 0.7206\n",
            "Test Accuracy: 0.7151\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "\n",
        "# Load the pre-trained VGG-16 model\n",
        "model2 = models.vgg16(pretrained=True)\n",
        "model2= model2.to(device)\n",
        "\n",
        "\n",
        "# Freeze all the layers in the pre-trained model\n",
        "for param in model2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last few layers\n",
        "for param in model2.features[-4:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Modify the last layer to match the number of classes in the CIFAR-10 dataset\n",
        "num_features = model2.classifier[6].in_features\n",
        "features = list(model2.classifier.children())[:-1] # Remove last layer\n",
        "features.extend([nn.Linear(num_features, 10)]) # Add our layer with 10 outputs\n",
        "model2.classifier = nn.Sequential(*features) # Replace the model classifier\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model2.parameters()), lr=0.001, momentum=0.9)\n",
        "model2 = model2.to(device)\n",
        "train_model(model2, train_loader, val_loader,optimizer,epochs=30)\n",
        "\n",
        "loss2,test_accuracy2 = evaluate(model2, test_loader)\n",
        "print(f\"Test Accuracy: {test_accuracy2:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After conducting experiments, it was found that the Multi-Layer Perceptron (MLP) model achieved a final accuracy of 50 percent on the dataset. However, it was observed that the MLP model has a large number of parameters. This becomes problematic, especially when dealing with images of larger sizes, as the model may overfit due to the sheer volume of parameters involved. Overfitting occurs when a model learns to memorize the training data rather than generalize well to unseen data.\n",
        "\n",
        "In contrast, the Convolutional Neural Network (CNN) model yielded a higher accuracy of 70 percent. There is potential for further improvement by increasing the number of training epochs. However, for the sake of comparison, the training was stopped at 70 percent accuracy. CNNs are particularly well-suited for image classification tasks due to their ability to automatically learn hierarchical patterns and features from the input data.\n",
        "\n",
        "Additionally, another approach involved utilizing a pretrained VGG16 model. It was found that this approach resulted in higher accuracy compared to both the MLP and CNN models when trained from scratch. Transfer learning, as demonstrated by using a pretrained model like VGG16, allows for leveraging knowledge learned from one task or dataset to improve performance on another task or dataset. This highlights the effectiveness of leveraging pretrained models, especially in scenarios where limited labeled data or computational resources are available."
      ],
      "metadata": {
        "id": "QBIOG7SnNqaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rIXdyAFsNpL7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}